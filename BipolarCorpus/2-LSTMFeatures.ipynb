{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook generates the data input to the LSTM models. It reads the (aligned) input modalities and computes a serialised version of the data. That is it generates temporal data using a sliding window. It also computes the dynamics for each feature (1st order derivative). In my dissertation, timesteps of 10, 30 and 60 frames were investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(no_data=False, eGeMAPS=False, verbose=False):\n",
    "    \"\"\"load preprocessed visual and acoustic features \n",
    "    \"\"\"\n",
    "    visual_dir = '/home/ceccarelli/Work/Bipolar/LLDs_video_openface_processed'\n",
    "    acoustic_dir = '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile_aligned/MFCCs' if not eGeMAPS else '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile_aligned/eGeMAPS'\n",
    "    output_dir = '/home/ceccarelli/Work/Bipolar/aligned_AV' if not eGeMAPS else '/home/ceccarelli/Work/Bipolar/aligned_EAV' \n",
    "\n",
    "    if no_data:\n",
    "        print(\"\\nprocessed files exist, starting loading (w/o raw data) ...\")\n",
    "        \n",
    "        y_train = pd.read_csv(os.path.join(output_dir, 'train_label.csv'), header=None) \n",
    "        inst_train = pd.read_csv(os.path.join(output_dir, 'train_inst.csv'), header=None) \n",
    "        y_dev = pd.read_csv(os.path.join(output_dir, 'dev_label.csv'), header=None)\n",
    "        inst_dev = pd.read_csv(os.path.join(output_dir, 'dev_inst.csv'), header=None)\n",
    "\n",
    "        if (verbose):\n",
    "            print(\"--\" * 20)\n",
    "            print(\"train label size\", y_train.T.shape)\n",
    "            print(\"dev label size\", y_dev.T.shape)\n",
    "            print(\"train inst size\", inst_train.T.shape)\n",
    "            print(\"dev inst size\", inst_dev.T.shape)\n",
    "            print(\"--\" * 20)\n",
    "        \n",
    "        return y_train.T.values, inst_train.T.values, y_dev.T.values, inst_dev.T.values\n",
    "\n",
    "    elif os.path.isfile(os.path.join(output_dir, 'train_data_A.csv')):\n",
    "        print(\"\\nprocessed files exist, starting loading ...\")\n",
    "        X_train_A = pd.read_csv(os.path.join(output_dir, 'train_data_A.csv'), header=None) \n",
    "        X_dev_A = pd.read_csv(os.path.join(output_dir, 'dev_data_A.csv'), header=None) \n",
    "        X_test_A = pd.read_csv(os.path.join(output_dir, 'test_data_A.csv'), header=None)\n",
    "        X_train_V = pd.read_csv(os.path.join(output_dir, 'train_data_V.csv'), header=None, low_memory=False)\n",
    "        X_dev_V = pd.read_csv(os.path.join(output_dir, 'dev_data_V.csv'), header=None, low_memory=False) \n",
    "        X_test_V = pd.read_csv(os.path.join(output_dir, 'test_data_V.csv'), header=None, low_memory=False)\n",
    "        y_train = pd.read_csv(os.path.join(output_dir, 'train_label.csv'), header=None) \n",
    "        inst_train = pd.read_csv(os.path.join(output_dir, 'train_inst.csv'), header=None) \n",
    "        y_dev = pd.read_csv(os.path.join(output_dir, 'dev_label.csv'), header=None) \n",
    "        inst_dev = pd.read_csv(os.path.join(output_dir, 'dev_inst.csv'), header=None)\n",
    "\n",
    "        if (verbose==True):\n",
    "            print(\"--\" * 20)\n",
    "            print(\"train data (A) size\", X_train_A.shape)\n",
    "            print(\"train data (V) size\", X_train_V.shape)\n",
    "            print(\"dev data (A) size\", X_dev_A.shape)\n",
    "            print(\"dev data (V) size\", X_dev_V.shape)\n",
    "            print(\"test data (A) size\", X_test_A.shape)\n",
    "            print(\"test data (V) size\", X_test_V.shape)\n",
    "            print(\"--\" * 20)\n",
    "            print(\"train label size\", y_train.T.shape)\n",
    "            print(\"dev label size\", y_dev.T.shape)\n",
    "            print(\"train inst size\", inst_train.T.shape)\n",
    "            print(\"dev inst size\", inst_dev.T.shape)\n",
    "            print(\"--\" * 20)\n",
    "\n",
    "        return X_train_A.iloc[:,1:], X_dev_A.iloc[:,1:], X_test_A.iloc[:,1:], X_train_V.iloc[:,1:], X_dev_V.iloc[:,1:], X_test_V.iloc[:,1:], y_train.T.values, inst_train.T.values, y_dev.T.values, inst_dev.T.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audioE modality\n",
      "\n",
      "processed files exist, starting loading ...\n",
      "----------------------------------------\n",
      "train data (A) size (759575, 70)\n",
      "train data (V) size (759575, 184)\n",
      "dev data (A) size (317104, 70)\n",
      "dev data (V) size (317104, 184)\n",
      "test data (A) size (372734, 70)\n",
      "test data (V) size (372734, 184)\n",
      "----------------------------------------\n",
      "train label size (759576, 1)\n",
      "dev label size (317105, 1)\n",
      "train inst size (759576, 1)\n",
      "dev inst size (317105, 1)\n",
      "----------------------------------------\n",
      "Autoencoder audioE train data has this shape (759575, 69)\n",
      "Autoencoder audioE dev data has this shape (317104, 69)\n"
     ]
    }
   ],
   "source": [
    "#select indexes for choosing which modality to serialise\n",
    "modalities = [\"visual\", \"audio\", \"audioE\"]\n",
    "visual_modalities = [\"facial\", \"gaze\", \"pose\", \"action\"]\n",
    "modality = modalities[2]\n",
    "visual_modality = visual_modalities[0]\n",
    "\n",
    "print (\"Loading %s modality\" %modality)\n",
    "\n",
    "if (modality == \"visual\"):\n",
    "    _, _, _, X_train_V, X_dev_V, _, _, _, _, _ = load(verbose=True)\n",
    "    if (visual_modality==\"facial\"):\n",
    "        print (\"Visual (facial)\")\n",
    "        X_train_V = X_train_V.iloc[:, :136] \n",
    "        X_dev_V = X_dev_V.iloc[:, :136] \n",
    "    elif (visual_modality==\"gaze\"):\n",
    "        print (\"Visual (gaze)\")\n",
    "        X_train_V = X_train_V.iloc[:, 136:142]\n",
    "        X_dev_V = X_dev_V.iloc[:, 136:142]\n",
    "    elif (visual_modality==\"pose\"):\n",
    "        print (\"Visual (pose)\")\n",
    "        X_train_V = X_train_V.iloc[:, 142:148] \n",
    "        X_dev_V = X_dev_V.iloc[:, 142:148] \n",
    "    else:\n",
    "        print (\"Visual (action)\")\n",
    "        X_train_V = X_train_V.iloc[:, 148:] \n",
    "        X_dev_V = X_dev_V.iloc[:, 148:] \n",
    "            \n",
    "            \n",
    "    X_train = X_train_V.to_numpy()\n",
    "    X_dev = X_dev_V.to_numpy()\n",
    "    \n",
    "    del X_train_V\n",
    "    del X_dev_V\n",
    "    \n",
    "    print (\"Autoencoder visual train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder visual dev data has this shape\", X_dev.shape)\n",
    "    \n",
    "elif (modality == \"audio\"):\n",
    "    X_train_A, X_dev_A, _, _, _, _, _, _, _, _ = load(verbose=True)\n",
    "    X_train = X_train_A.to_numpy()\n",
    "    X_dev = X_dev_A.to_numpy()\n",
    "    \n",
    "    del X_train_A\n",
    "    del X_dev_A\n",
    "    \n",
    "    print (\"Autoencoder audio train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder audio dev data has this shape\", X_dev.shape)\n",
    "    \n",
    "else:\n",
    "    X_train_A, X_dev_A, _, _, _, _, _, _, _, _ = load(eGeMAPS=True, verbose=True)\n",
    "    X_train = X_train_A.to_numpy()\n",
    "    X_dev = X_dev_A.to_numpy()\n",
    "    \n",
    "    del X_train_A\n",
    "    del X_dev_A\n",
    "    \n",
    "    print (\"Autoencoder audioE train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder audioE dev data has this shape\", X_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamics(X_0th, time=0.1):\n",
    "    \"\"\"compute dynamics for data (1st)\"\"\"\n",
    "    X_1st = np.zeros((X_0th.shape[0]-1, X_0th.shape[1]))\n",
    "    for i in range(X_0th.shape[0]-1):\n",
    "        X_1st[i] = (X_0th[i+1] - X_0th[i]) / time\n",
    "    return X_1st\n",
    "\n",
    "def frame2session(X, y, inst, verbose=False):\n",
    "    # para X: data\n",
    "    # para y: label\n",
    "    # para inst: instance\n",
    "    print(X.shape, y.shape, inst.shape)\n",
    "    X = np.asarray(X)\n",
    "    assert X.shape[0] == y.shape[0] == inst.shape[0]\n",
    "    if y.shape[1] == 1:\n",
    "        y = y[:,0]\n",
    "    if inst.shape[1] == 1:\n",
    "        inst = inst[:,0]\n",
    "    \n",
    "    max_inst = int(max(inst))\n",
    "    min_inst = int(min(inst))\n",
    "    X_sess, y_sess = [], []\n",
    "    for i in range(min_inst, max_inst+1):\n",
    "        idx = np.where(inst == i)[0]\n",
    "        X_temp = X[idx]\n",
    "        y_temp = y[idx]\n",
    "        X_sess.append(X_temp)\n",
    "        if len(set(y_temp)) == 1:\n",
    "            y_sess.append(y_temp[0])\n",
    "        if verbose:\n",
    "            print(\"instance %d data shape\" % i, X_temp.shape)\n",
    "    assert max_inst == len(X_sess) == len(y_sess)\n",
    "    return np.array(X_sess), np.array(y_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "processed files exist, starting loading (w/o raw data) ...\n",
      "----------------------------------------\n",
      "train label size (759576, 1)\n",
      "dev label size (317105, 1)\n",
      "train inst size (759576, 1)\n",
      "dev inst size (317105, 1)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_train_frame, inst_train, y_dev_frame, inst_dev = load(no_data=True, verbose=True)\n",
    "y_train_frame = y_train_frame[:-1,:]\n",
    "inst_train = inst_train[:-1,:]\n",
    "y_dev_frame = y_dev_frame[:-1,:]\n",
    "inst_dev = inst_dev[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759575, 69) (759575, 1) (759575, 1)\n",
      "(317104, 69) (317104, 1) (317104, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_session, y_train_session = frame2session(X_train, y_train_frame, inst_train, verbose=False)\n",
    "X_dev_session, y_dev_session = frame2session(X_dev, y_dev_frame, inst_dev, verbose=False)\n",
    "\n",
    "#save the frame session labels \n",
    "#change directory as needed\n",
    "np.save(\"../TemporalData30/session_label_train.npy\", np.asarray(y_train_session))\n",
    "np.save(\"../TemporalData30/session_label_dev.npy\", np.asarray(y_dev_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current length of train data is  104\n",
      "Current length of dev data is  60\n",
      "(756351, 30, 69)\n",
      "(315244, 30, 69)\n"
     ]
    }
   ],
   "source": [
    "#serialise the data using a loop back of variable length (10, 30 and 60)\n",
    "X_train = list()\n",
    "x_train_length = list()\n",
    "\n",
    "for i in X_train_session:\n",
    "\n",
    "    look_back = 30\n",
    "    tmp = get_dynamics(i)\n",
    "    nb_samples = tmp.shape[0] - look_back\n",
    "    x_train_reshaped = np.zeros((nb_samples, look_back, tmp.shape[1]))\n",
    "\n",
    "    for k in range(nb_samples):\n",
    "        y_position = k + look_back\n",
    "        x_train_reshaped[k] = tmp[k:y_position]\n",
    "    X_train.append(x_train_reshaped)\n",
    "    x_train_length.append(x_train_reshaped.shape[0])\n",
    "\n",
    "print (\"Current length of train data is \", len(X_train))\n",
    "\n",
    "X_dev = list()\n",
    "x_dev_length = list()\n",
    "\n",
    "for i in X_dev_session:\n",
    "\n",
    "    look_back = 30\n",
    "    tmp = get_dynamics(i)\n",
    "    nb_samples = tmp.shape[0] - look_back\n",
    "    x_dev_reshaped = np.zeros((nb_samples, look_back, tmp.shape[1]))\n",
    "\n",
    "    for k in range(nb_samples):\n",
    "        y_position = k + look_back\n",
    "        x_dev_reshaped[k] = tmp[k:y_position]\n",
    "    X_dev.append(x_dev_reshaped)\n",
    "    x_dev_length.append(x_dev_reshaped.shape[0])\n",
    "    \n",
    "print (\"Current length of dev data is \", len(X_dev))\n",
    "\n",
    "#store the lenght of each video in terms of frames so it is easy to recontrust all the video sequences\n",
    "x_train_length = np.asarray(x_train_length)\n",
    "x_dev_length = np.asarray(x_dev_length)\n",
    "np.save(\"../TemporalData30/train_length.npy\", x_train_length)\n",
    "np.save(\"../TemporalData30/dev_length.npy\", x_dev_length)\n",
    "\n",
    "\n",
    "#save the dynamic, sequential features \n",
    "X_train = np.vstack((X_train))\n",
    "X_dev = np.vstack((X_dev))\n",
    "\n",
    "#change path and name as needed\n",
    "np.save(\"../TemporalData30/train_audioE.npy\", X_train)\n",
    "np.save(\"../TemporalData30/dev_audioE.npy\", X_dev)\n",
    "print (X_train.shape)\n",
    "print (X_dev.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
