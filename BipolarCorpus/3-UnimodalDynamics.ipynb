{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used to train unimodal LSTM autoencoders and save the encoded representation. It also computes the FV from the encoded representation, performs feature selection and Random Forest Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/home/ceccarelli/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import itertools as it\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Masking\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data for training unimodal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio modality\n",
      "Autoencoder audio train data has this shape (753231, 60, 117)\n",
      "Autoencoder audio dev data has this shape (313444, 60, 117)\n"
     ]
    }
   ],
   "source": [
    "modalities = [\"visual\", \"audio\", \"audioE\"]\n",
    "visual_modalities = [\"facial\", \"gaze\", \"pose\", \"action\"]\n",
    "modality = modalities[1]\n",
    "visual_modality = visual_modalities[0]\n",
    "\n",
    "print (\"Loading %s modality\" %modality)\n",
    "\n",
    "if (modality == \"visual\"):\n",
    "    \n",
    "    if (visual_modality==\"facial\"):\n",
    "        X_train = np.load(\"../TemporalData60/train_landmarks.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_landmarks.npy\")\n",
    "        \n",
    "    elif (visual_modality==\"gaze\"):\n",
    "        X_train = np.load(\"../TemporalData60/train_gaze.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_gaze.npy\")\n",
    "        \n",
    "    elif (visual_modality==\"pose\"):\n",
    "        X_train = np.load(\"../TemporalData60/train_pose.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_pose.npy\")\n",
    "        \n",
    "    else:\n",
    "        X_train = np.load(\"../TemporalData60/train_action.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_action.npy\")\n",
    "            \n",
    "    \n",
    "    print (\"Autoencoder visual train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder visual dev data has this shape\", X_dev.shape)\n",
    "    \n",
    "elif (modality == \"audio\"):\n",
    "    \n",
    "    X_train = np.load(\"../TemporalData60/train_audio.npy\")\n",
    "    X_dev = np.load(\"../TemporalData60/dev_audio.npy\")\n",
    "    \n",
    "    print (\"Autoencoder audio train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder audio dev data has this shape\", X_dev.shape)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    X_train = np.load(\"../TemporalData60/train_audioE.npy\")\n",
    "    X_dev = np.load(\"../TemporalData60/dev_audioE.npy\")\n",
    "    \n",
    "    print (\"Autoencoder audioE train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder audioE dev data has this shape\", X_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1066675, 60, 117)\n"
     ]
    }
   ],
   "source": [
    "#put data together for the autoencoder training\n",
    "X = np.vstack((X_train, X_dev))\n",
    "del X_train\n",
    "del X_dev\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden dimension 35\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "----------------------------------------\n",
      "autoencoder\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 117)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 70)                42840     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 60, 70)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 60, 70)            29680     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 117)           8307      \n",
      "=================================================================\n",
      "Total params: 80,827\n",
      "Trainable params: 80,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------\n",
      "encoder\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 117)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 70)                42840     \n",
      "=================================================================\n",
      "Total params: 42,840\n",
      "Trainable params: 42,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#MODEL DEFINITION\n",
    "hidden_ratio = 0.3\n",
    "timesteps, n_features = X.shape[1] , X.shape[2]\n",
    "dimensions_lstm = round(n_features*hidden_ratio)\n",
    "print ('Hidden dimension %i' %dimensions_lstm)\n",
    "# encoder part\n",
    "# input placeholder\n",
    "input_data = Input(shape=(timesteps, n_features))\n",
    "encoded = Bidirectional(LSTM(dimensions_lstm, activation='relu', return_sequences=False))(input_data)\n",
    "#connection between encoder and decoder\n",
    "middle_representation = RepeatVector(timesteps)(encoded)\n",
    "# decoder part\n",
    "decoded = Bidirectional(LSTM(dimensions_lstm, activation='relu', return_sequences=True))(middle_representation)\n",
    "decoded = TimeDistributed(Dense(n_features, activation = 'linear'))(decoded)\n",
    "autoencoder = Model(input_data, decoded)\n",
    "encoder = Model(input_data, encoded)\n",
    "# for clipping gradients\n",
    "#ADAM = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False, clipnorm=0.5)\n",
    "#autoencoder.compile(loss='mae', optimizer=ADAM)\n",
    "autoencoder.compile(loss='mae', optimizer=\"adam\")\n",
    "print(\"--\" * 20)\n",
    "print(\"autoencoder\")\n",
    "print(autoencoder.summary())\n",
    "print(\"--\" * 20)\n",
    "print(\"encoder\")\n",
    "print(encoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory and save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../FINAL_RESULTS_60'\n",
    "feature_type = 'MFCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35  Created \n"
     ]
    }
   ],
   "source": [
    "save_dir = save_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    print(\"Directory \" , save_dir ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , save_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1066675/1066675 [==============================] - 352s 330us/step - loss: 697.8773\n",
      "\n",
      "Epoch 00001: loss improved from inf to 697.87732, saving model to ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/weights-improvement-01-697.88.hdf5\n",
      "Epoch 2/5\n",
      "1066675/1066675 [==============================] - 338s 317us/step - loss: 687.3134\n",
      "\n",
      "Epoch 00002: loss improved from 697.87732 to 687.31336, saving model to ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/weights-improvement-02-687.31.hdf5\n",
      "Epoch 3/5\n",
      "1066675/1066675 [==============================] - 338s 317us/step - loss: 222.9379\n",
      "\n",
      "Epoch 00003: loss improved from 687.31336 to 222.93786, saving model to ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/weights-improvement-03-222.94.hdf5\n",
      "Epoch 4/5\n",
      "1066675/1066675 [==============================] - 338s 317us/step - loss: 220.9236\n",
      "\n",
      "Epoch 00004: loss improved from 222.93786 to 220.92364, saving model to ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/weights-improvement-04-220.92.hdf5\n",
      "Epoch 5/5\n",
      "1066675/1066675 [==============================] - 339s 318us/step - loss: 243.0623\n",
      "\n",
      "Epoch 00005: loss did not improve from 220.92364\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "csv_logger = CSVLogger(os.path.join(save_dir, \"logger.csv\"))\n",
    "checkpoint = ModelCheckpoint(os.path.join(save_dir, \"weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"), \n",
    "                             monitor='loss', \n",
    "                             verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [csv_logger, checkpoint]\n",
    "\n",
    "hist = autoencoder.fit(X, X, epochs=20,\n",
    "                batch_size=5120,\n",
    "                callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Loss'], loc='upper right')\n",
    "plt.savefig(os.path.join(save_dir, 'LOSS.png'))\n",
    "plt.show()\n",
    "autoencoder.save_weights(os.path.join(save_dir, 'BI_LSTM_DYNAMICS.h5'))\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model is trained -- Encod train and dev sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading audio modality\n",
      "Autoencoder audio train data has this shape (753231, 60, 117)\n",
      "Autoencoder audio dev data has this shape (313444, 60, 117)\n"
     ]
    }
   ],
   "source": [
    "print (\"Loading %s modality\" %modality)\n",
    "\n",
    "if (modality == \"visual\"):\n",
    "    \n",
    "    if (visual_modality==\"facial\"):\n",
    "        X_train = np.load(\"../TemporalData60/train_landmarks.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_landmarks.npy\")\n",
    "        \n",
    "    elif (visual_modality==\"gaze\"):\n",
    "        X_train = np.load(\"../TemporalData60/train_gaze.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_gaze.npy\")\n",
    "        \n",
    "    elif (visual_modality==\"pose\"):\n",
    "        X_train = np.load(\"../TemporalData60/train_pose.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_pose.npy\")\n",
    "        \n",
    "    else:\n",
    "        X_train = np.load(\"../TemporalData60/train_action.npy\")\n",
    "        X_dev = np.load(\"../TemporalData60/dev_action.npy\")\n",
    "            \n",
    "    \n",
    "    print (\"Autoencoder visual train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder visual dev data has this shape\", X_dev.shape)\n",
    "    \n",
    "elif (modality == \"audio\"):\n",
    "    \n",
    "    X_train = np.load(\"../TemporalData60/train_audio.npy\")\n",
    "    X_dev = np.load(\"../TemporalData60/dev_audio.npy\")\n",
    "    \n",
    "    \n",
    "    print (\"Autoencoder audio train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder audio dev data has this shape\", X_dev.shape)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    X_train = np.load(\"../TemporalData60/train_audioE.npy\")\n",
    "    X_dev = np.load(\"../TemporalData60/dev_audioE.npy\")\n",
    "    \n",
    "    print (\"Autoencoder audioE train data has this shape\", X_train.shape)\n",
    "    print (\"Autoencoder audioE dev data has this shape\", X_dev.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding representation\n",
      "Encoding train done\n",
      "Encoding done!\n"
     ]
    }
   ],
   "source": [
    "print ('Encoding representation')\n",
    "encoded_train = encoder.predict(X_train)\n",
    "print ('Encoding train done')\n",
    "encoded_dev = encoder.predict(X_dev)\n",
    "print ('Encoding done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/encoding  Created \n"
     ]
    }
   ],
   "source": [
    "encoded_dir = '../FINAL_RESULTS_60'\n",
    "encoded_dir = encoded_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)+'/encoding'\n",
    "if not os.path.exists(encoded_dir):\n",
    "    os.mkdir(encoded_dir)\n",
    "    print(\"Directory \" , encoded_dir ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , encoded_dir ,  \" already exists\")\n",
    "    \n",
    "np.save(os.path.join(encoded_dir, 'encoded_train'), encoded_train)\n",
    "np.save(os.path.join(encoded_dir, 'encoded_dev'), encoded_dev)\n",
    "del X_train\n",
    "del X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame2session(encoded_dir, x_train_length, x_dev_length):\n",
    "    tmp = list()\n",
    "    tmp2 = list()\n",
    "    X_train_frame = np.load(encoded_dir + \"/encoded_train.npy\")\n",
    "    indices = np.zeros((len(x_train_length)+1))\n",
    "    indices[0] = 0\n",
    "    for i in range(1, len(x_train_length)):\n",
    "        indices[i] = indices[i-1] + x_train_length[i-1]\n",
    "    indices[len(x_train_length)] = sum(x_train_length)-1 \n",
    "    for i in range(len(indices)-1):\n",
    "        tmp.append(X_train_frame[int(indices[i]):int(indices[i+1]),:])\n",
    "        \n",
    "    X_dev_frame = np.load(encoded_dir + \"/encoded_dev.npy\")\n",
    "    indices2 = np.zeros((len(x_dev_length)+1))\n",
    "    indices2[0] = 0\n",
    "    for i in range(1, len(x_dev_length)):\n",
    "        indices2[i] = indices2[i-1] + x_dev_length[i-1]\n",
    "    indices2[len(x_dev_length)] = sum(x_dev_length)-1 \n",
    "    for i in range(len(indices2)-1):\n",
    "        tmp2.append(X_dev_frame[int(indices2[i]):int(indices2[i+1]),:])\n",
    "        \n",
    "    return tmp, tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_vector(xx, gmm, normalized=True):\n",
    "    \"\"\"Computes the Fisher vector on a set of descriptors.\n",
    "    Parameters\n",
    "    ----------\n",
    "    xx: array_like, shape (N, D) or (D, )\n",
    "        The set of descriptors\n",
    "    gmm: instance of sklearn mixture.GMM object\n",
    "        Gauassian mixture model of the descriptors.\n",
    "    Returns\n",
    "    -------\n",
    "    fv: array_like, shape (K + 2 * D * K, )\n",
    "        Fisher vector (derivatives with respect to the mixing weights, means\n",
    "        and variances) of the given descriptors.\n",
    "    \"\"\"\n",
    "    xx = np.atleast_2d(xx)\n",
    "    N = xx.shape[0]\n",
    "\n",
    "    # Compute posterior probabilities.\n",
    "    Q = gmm.predict_proba(xx)  # NxK\n",
    "\n",
    "    # Compute the sufficient statistics of descriptors.\n",
    "    Q_sum = np.sum(Q, 0)[:, np.newaxis] / N\n",
    "    Q_xx = np.dot(Q.T, xx) / N\n",
    "    Q_xx_2 = np.dot(Q.T, xx ** 2) / N\n",
    "\n",
    "    # Compute derivatives with respect to mixing weights, means and variances.\n",
    "    d_pi = Q_sum.squeeze() - gmm.weights_\n",
    "    d_mu = Q_xx - Q_sum * gmm.means_\n",
    "    d_sigma = (\n",
    "        - Q_xx_2\n",
    "        - Q_sum * gmm.means_ ** 2\n",
    "        + Q_sum * gmm.covars_\n",
    "        + 2 * Q_xx * gmm.means_)\n",
    "\n",
    "    # Merge derivatives into a vector.\n",
    "    fisher =  np.hstack((d_pi, d_mu.flatten(), d_sigma.flatten()))\n",
    "    if normalized:\n",
    "            fisher = np.sqrt(np.abs(fisher)) * np.sign(fisher) # power normalization\n",
    "            fisher = fisher / np.linalg.norm(fisher, axis=0) # L2 norm\n",
    "            \n",
    "    return fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "x_train_length = np.load(\"../TemporalData60/train_length.npy\")\n",
    "x_dev_length = np.load(\"../TemporalData60/dev_length.npy\")\n",
    "\n",
    "y_train_session = np.load(\"../TemporalData60/session_label_train.npy\")\n",
    "y_dev_session = np.load(\"../TemporalData60/session_label_dev.npy\")\n",
    "\n",
    "X_frame_train, X_frame_dev = frame2session(encoded_dir, x_train_length, x_dev_length)\n",
    "print (len(X_frame_train))\n",
    "print (len(X_frame_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/encoding  already exists\n",
      "Directory  ../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/fisherVectors  Created \n",
      "Computing kernel 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ceccarelli/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/ceccarelli/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/ceccarelli/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing kernel 32\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "encoded_dir = '../FINAL_RESULTS_60'\n",
    "encoded_dir = encoded_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)+'/encoding'\n",
    "if not os.path.exists(encoded_dir):\n",
    "    os.mkdir(encoded_dir)\n",
    "    print(\"Directory \" , encoded_dir ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , encoded_dir ,  \" already exists\")\n",
    "    \n",
    "    \n",
    "save_dir = '../FINAL_RESULTS_60'\n",
    "save_dir = save_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)+'/fisherVectors'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "    print(\"Directory \" , save_dir ,  \" Created \")\n",
    "else:    \n",
    "    print(\"Directory \" , save_dir ,  \" already exists\")\n",
    "    \n",
    "X_train_session, X_dev_session = frame2session(encoded_dir, x_train_length, x_dev_length)\n",
    "\n",
    "    \n",
    "kernels = [16 , 32]\n",
    "for kernel in kernels:\n",
    "    \n",
    "    print ('Computing kernel %i' %kernel)\n",
    "    fv_train, fv_dev = [], []\n",
    "\n",
    "    for X_train in X_train_session:\n",
    "        gmm = GMM(n_components=kernel, covariance_type='diag')\n",
    "        gmm.fit(X_train)\n",
    "        fv = fisher_vector(X_train, gmm)\n",
    "        fv_train.append(fv)\n",
    "\n",
    "    for X_dev in X_dev_session:\n",
    "        gmm = GMM(n_components=kernel, covariance_type='diag')\n",
    "        gmm.fit(X_dev)\n",
    "        fv = fisher_vector(X_dev, gmm)\n",
    "        fv_dev.append(fv)\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'fisher_vector_train_%i' %kernel), fv_train)\n",
    "    np.save(os.path.join(save_dir, 'fisher_vector_dev_%i' %kernel), fv_dev)\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'session_label_train'), y_train_session)\n",
    "    np.save(os.path.join(save_dir, 'session_label_dev'), y_dev_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 2256)\n",
      "(60, 2256)\n",
      "(104,)\n",
      "(60,)\n",
      "   feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "0  -0.000189 -1.240461e-09 -1.240461e-09 -1.240461e-09 -1.240461e-09   \n",
      "1   0.000464 -2.906718e-04  4.016815e-04 -2.732629e-04  2.567710e-04   \n",
      "2   0.000002 -1.294160e-12 -1.294160e-12 -1.283455e-06 -1.283455e-06   \n",
      "3  -0.001671 -1.352141e-09 -1.352224e-09 -1.352224e-09 -1.352348e-09   \n",
      "4   0.000322 -1.589314e-09  6.289694e-04  6.923613e-04  8.650825e-05   \n",
      "\n",
      "      feature_5     feature_6     feature_7     feature_8     feature_9  ...  \\\n",
      "0 -1.240157e-09 -1.240461e-09 -8.050809e-04  2.020904e-03 -1.873505e-03  ...   \n",
      "1  1.235931e-03  1.172229e-04  3.995294e-04 -3.916362e-04  1.271855e-04  ...   \n",
      "2  2.563476e-06 -1.283455e-06 -1.283455e-06 -1.283455e-06 -1.294160e-12  ...   \n",
      "3  3.705039e-08 -1.352348e-09 -1.352348e-09 -1.364961e-09  1.670584e-03  ...   \n",
      "4  3.271429e-04 -5.832298e-04  1.036471e-04 -7.497531e-04  1.245722e-03  ...   \n",
      "\n",
      "   feature_2246  feature_2247  feature_2248  feature_2249  feature_2250  \\\n",
      "0      0.000114      0.000097      0.000097      0.000097      0.000097   \n",
      "1     -0.064141     -0.074240     -0.067283     -0.067417     -0.051893   \n",
      "2     -0.000014     -0.000006      0.000001      0.000001      0.000009   \n",
      "3      0.000026      0.000026      0.000026      0.000026      0.000026   \n",
      "4     -0.025723      0.012462     -0.006929      0.007741     -0.003592   \n",
      "\n",
      "   feature_2251  feature_2252  feature_2253  feature_2254  feature_2255  \n",
      "0      0.000097      0.000097      0.000097      0.000097      0.000097  \n",
      "1     -0.062469     -0.042017     -0.046852     -0.081132      0.188506  \n",
      "2      0.000001      0.000001     -0.000009      0.000003     -0.000011  \n",
      "3     -0.000269      0.000026      0.000026      0.000026      0.000026  \n",
      "4      0.018152      0.001194     -0.025290     -0.010779     -0.019390  \n",
      "\n",
      "[5 rows x 2256 columns]\n",
      "\n",
      "feature importance ranking\n",
      "1. feature 845 feature_845 (0.003482)\n",
      "2. feature 394 feature_394 (0.003171)\n",
      "3. feature 1475 feature_1475 (0.002842)\n",
      "4. feature 1026 feature_1026 (0.002569)\n",
      "5. feature 2146 feature_2146 (0.002563)\n",
      "6. feature 1965 feature_1965 (0.002555)\n",
      "7. feature 1031 feature_1031 (0.002460)\n",
      "8. feature 2228 feature_2228 (0.002424)\n",
      "9. feature 2130 feature_2130 (0.002400)\n",
      "10. feature 1138 feature_1138 (0.002391)\n",
      "11. feature 1128 feature_1128 (0.002185)\n",
      "12. feature 2232 feature_2232 (0.002157)\n",
      "13. feature 1326 feature_1326 (0.002151)\n",
      "14. feature 2151 feature_2151 (0.002108)\n",
      "15. feature 1259 feature_1259 (0.001917)\n",
      "16. feature 1157 feature_1157 (0.001884)\n",
      "17. feature 1816 feature_1816 (0.001845)\n",
      "18. feature 1528 feature_1528 (0.001803)\n",
      "19. feature 1158 feature_1158 (0.001749)\n",
      "20. feature 2239 feature_2239 (0.001686)\n",
      "21. feature 1526 feature_1526 (0.001679)\n",
      "22. feature 829 feature_829 (0.001653)\n",
      "23. feature 2203 feature_2203 (0.001651)\n",
      "24. feature 355 feature_355 (0.001646)\n",
      "25. feature 1058 feature_1058 (0.001639)\n",
      "26. feature 1154 feature_1154 (0.001621)\n",
      "27. feature 1501 feature_1501 (0.001610)\n",
      "28. feature 1073 feature_1073 (0.001555)\n",
      "29. feature 29 feature_29 (0.001522)\n",
      "30. feature 381 feature_381 (0.001511)\n",
      "31. feature 1949 feature_1949 (0.001492)\n",
      "32. feature 1685 feature_1685 (0.001483)\n",
      "33. feature 72 feature_72 (0.001481)\n",
      "34. feature 2159 feature_2159 (0.001473)\n",
      "35. feature 386 feature_386 (0.001471)\n",
      "36. feature 1546 feature_1546 (0.001438)\n",
      "37. feature 1908 feature_1908 (0.001436)\n",
      "38. feature 1230 feature_1230 (0.001423)\n",
      "39. feature 2034 feature_2034 (0.001415)\n",
      "40. feature 37 feature_37 (0.001411)\n",
      "41. feature 1735 feature_1735 (0.001409)\n",
      "42. feature 2229 feature_2229 (0.001384)\n",
      "43. feature 1457 feature_1457 (0.001376)\n",
      "44. feature 1743 feature_1743 (0.001373)\n",
      "45. feature 1030 feature_1030 (0.001358)\n",
      "46. feature 1458 feature_1458 (0.001356)\n",
      "47. feature 1179 feature_1179 (0.001342)\n",
      "48. feature 1269 feature_1269 (0.001339)\n",
      "49. feature 2093 feature_2093 (0.001330)\n",
      "50. feature 1381 feature_1381 (0.001329)\n",
      "(104, 50) (60, 50)\n",
      "(104, 2256)\n",
      "(60, 2256)\n",
      "(104,)\n",
      "(60,)\n",
      "   feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "0  -0.000189 -1.240461e-09 -1.240461e-09 -1.240461e-09 -1.240461e-09   \n",
      "1   0.000464 -2.906718e-04  4.016815e-04 -2.732629e-04  2.567710e-04   \n",
      "2   0.000002 -1.294160e-12 -1.294160e-12 -1.283455e-06 -1.283455e-06   \n",
      "3  -0.001671 -1.352141e-09 -1.352224e-09 -1.352224e-09 -1.352348e-09   \n",
      "4   0.000322 -1.589314e-09  6.289694e-04  6.923613e-04  8.650825e-05   \n",
      "\n",
      "      feature_5     feature_6     feature_7     feature_8     feature_9  ...  \\\n",
      "0 -1.240157e-09 -1.240461e-09 -8.050809e-04  2.020904e-03 -1.873505e-03  ...   \n",
      "1  1.235931e-03  1.172229e-04  3.995294e-04 -3.916362e-04  1.271855e-04  ...   \n",
      "2  2.563476e-06 -1.283455e-06 -1.283455e-06 -1.283455e-06 -1.294160e-12  ...   \n",
      "3  3.705039e-08 -1.352348e-09 -1.352348e-09 -1.364961e-09  1.670584e-03  ...   \n",
      "4  3.271429e-04 -5.832298e-04  1.036471e-04 -7.497531e-04  1.245722e-03  ...   \n",
      "\n",
      "   feature_2246  feature_2247  feature_2248  feature_2249  feature_2250  \\\n",
      "0      0.000114      0.000097      0.000097      0.000097      0.000097   \n",
      "1     -0.064141     -0.074240     -0.067283     -0.067417     -0.051893   \n",
      "2     -0.000014     -0.000006      0.000001      0.000001      0.000009   \n",
      "3      0.000026      0.000026      0.000026      0.000026      0.000026   \n",
      "4     -0.025723      0.012462     -0.006929      0.007741     -0.003592   \n",
      "\n",
      "   feature_2251  feature_2252  feature_2253  feature_2254  feature_2255  \n",
      "0      0.000097      0.000097      0.000097      0.000097      0.000097  \n",
      "1     -0.062469     -0.042017     -0.046852     -0.081132      0.188506  \n",
      "2      0.000001      0.000001     -0.000009      0.000003     -0.000011  \n",
      "3     -0.000269      0.000026      0.000026      0.000026      0.000026  \n",
      "4      0.018152      0.001194     -0.025290     -0.010779     -0.019390  \n",
      "\n",
      "[5 rows x 2256 columns]\n",
      "\n",
      "feature importance ranking\n",
      "1. feature 2146 feature_2146 (0.003069)\n",
      "2. feature 1965 feature_1965 (0.002943)\n",
      "3. feature 1026 feature_1026 (0.002685)\n",
      "4. feature 1255 feature_1255 (0.002373)\n",
      "5. feature 1743 feature_1743 (0.002280)\n",
      "6. feature 2228 feature_2228 (0.002209)\n",
      "7. feature 2239 feature_2239 (0.002124)\n",
      "8. feature 2130 feature_2130 (0.002122)\n",
      "9. feature 1128 feature_1128 (0.002070)\n",
      "10. feature 1475 feature_1475 (0.002039)\n",
      "11. feature 2035 feature_2035 (0.002000)\n",
      "12. feature 935 feature_935 (0.001935)\n",
      "13. feature 1031 feature_1031 (0.001935)\n",
      "14. feature 1528 feature_1528 (0.001927)\n",
      "15. feature 1973 feature_1973 (0.001911)\n",
      "16. feature 845 feature_845 (0.001905)\n",
      "17. feature 1326 feature_1326 (0.001867)\n",
      "18. feature 2232 feature_2232 (0.001859)\n",
      "19. feature 1381 feature_1381 (0.001811)\n",
      "20. feature 16 feature_16 (0.001709)\n",
      "21. feature 788 feature_788 (0.001702)\n",
      "22. feature 1483 feature_1483 (0.001697)\n",
      "23. feature 37 feature_37 (0.001694)\n",
      "24. feature 2151 feature_2151 (0.001694)\n",
      "25. feature 1517 feature_1517 (0.001685)\n",
      "26. feature 829 feature_829 (0.001674)\n",
      "27. feature 1157 feature_1157 (0.001638)\n",
      "28. feature 1158 feature_1158 (0.001635)\n",
      "29. feature 1304 feature_1304 (0.001585)\n",
      "30. feature 2229 feature_2229 (0.001556)\n",
      "31. feature 1628 feature_1628 (0.001549)\n",
      "32. feature 1224 feature_1224 (0.001539)\n",
      "33. feature 1230 feature_1230 (0.001538)\n",
      "34. feature 1138 feature_1138 (0.001525)\n",
      "35. feature 2248 feature_2248 (0.001516)\n",
      "36. feature 1154 feature_1154 (0.001504)\n",
      "37. feature 1949 feature_1949 (0.001500)\n",
      "38. feature 1388 feature_1388 (0.001479)\n",
      "39. feature 2080 feature_2080 (0.001474)\n",
      "40. feature 1229 feature_1229 (0.001456)\n",
      "41. feature 689 feature_689 (0.001444)\n",
      "42. feature 450 feature_450 (0.001433)\n",
      "43. feature 1501 feature_1501 (0.001394)\n",
      "44. feature 1194 feature_1194 (0.001381)\n",
      "45. feature 2183 feature_2183 (0.001371)\n",
      "46. feature 978 feature_978 (0.001353)\n",
      "47. feature 1826 feature_1826 (0.001332)\n",
      "48. feature 701 feature_701 (0.001324)\n",
      "49. feature 2156 feature_2156 (0.001323)\n",
      "50. feature 51 feature_51 (0.001315)\n",
      "51. feature 1685 feature_1685 (0.001315)\n",
      "52. feature 1816 feature_1816 (0.001301)\n",
      "53. feature 426 feature_426 (0.001298)\n",
      "54. feature 1950 feature_1950 (0.001295)\n",
      "55. feature 1735 feature_1735 (0.001271)\n",
      "56. feature 2150 feature_2150 (0.001252)\n",
      "57. feature 1030 feature_1030 (0.001243)\n",
      "58. feature 2141 feature_2141 (0.001238)\n",
      "59. feature 1151 feature_1151 (0.001238)\n",
      "60. feature 960 feature_960 (0.001235)\n",
      "61. feature 1197 feature_1197 (0.001229)\n",
      "62. feature 2158 feature_2158 (0.001228)\n",
      "63. feature 2202 feature_2202 (0.001217)\n",
      "64. feature 349 feature_349 (0.001211)\n",
      "65. feature 2132 feature_2132 (0.001211)\n",
      "66. feature 1668 feature_1668 (0.001206)\n",
      "67. feature 2208 feature_2208 (0.001206)\n",
      "68. feature 2142 feature_2142 (0.001203)\n",
      "69. feature 1908 feature_1908 (0.001201)\n",
      "70. feature 1319 feature_1319 (0.001198)\n",
      "71. feature 1806 feature_1806 (0.001196)\n",
      "72. feature 567 feature_567 (0.001193)\n",
      "73. feature 915 feature_915 (0.001177)\n",
      "74. feature 1058 feature_1058 (0.001176)\n",
      "75. feature 1466 feature_1466 (0.001174)\n",
      "76. feature 18 feature_18 (0.001173)\n",
      "77. feature 1802 feature_1802 (0.001167)\n",
      "78. feature 1386 feature_1386 (0.001166)\n",
      "79. feature 386 feature_386 (0.001165)\n",
      "80. feature 2159 feature_2159 (0.001163)\n",
      "81. feature 1039 feature_1039 (0.001161)\n",
      "82. feature 1405 feature_1405 (0.001160)\n",
      "83. feature 1598 feature_1598 (0.001153)\n",
      "84. feature 1878 feature_1878 (0.001151)\n",
      "85. feature 1177 feature_1177 (0.001147)\n",
      "86. feature 2087 feature_2087 (0.001145)\n",
      "87. feature 394 feature_394 (0.001134)\n",
      "88. feature 1767 feature_1767 (0.001130)\n",
      "89. feature 2236 feature_2236 (0.001129)\n",
      "90. feature 2018 feature_2018 (0.001127)\n",
      "91. feature 1136 feature_1136 (0.001126)\n",
      "92. feature 1858 feature_1858 (0.001121)\n",
      "93. feature 1208 feature_1208 (0.001119)\n",
      "94. feature 1479 feature_1479 (0.001118)\n",
      "95. feature 2190 feature_2190 (0.001113)\n",
      "96. feature 1199 feature_1199 (0.001109)\n",
      "97. feature 2081 feature_2081 (0.001106)\n",
      "98. feature 1292 feature_1292 (0.001100)\n",
      "99. feature 1142 feature_1142 (0.001094)\n",
      "100. feature 2163 feature_2163 (0.001092)\n",
      "(104, 100) (60, 100)\n",
      "(104, 4512)\n",
      "(60, 4512)\n",
      "(104,)\n",
      "(60,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "0 -2.763211e-05 -1.479029e-09 -1.479029e-09 -1.479029e-09 -1.479029e-09   \n",
      "1 -1.027932e-03  1.454592e-04 -1.003147e-04  2.046178e-04  3.832301e-05   \n",
      "2 -8.431040e-07 -1.217126e-12 -1.217126e-12 -1.206173e-06 -1.206173e-06   \n",
      "3 -1.014059e-06 -7.238331e-06 -1.183598e-11 -1.183273e-11 -1.183128e-11   \n",
      "4  2.981465e-04 -2.129531e-09 -2.652456e-04 -4.007589e-04  6.296440e-04   \n",
      "\n",
      "      feature_5     feature_6     feature_7     feature_8     feature_9  ...  \\\n",
      "0 -1.479029e-09  1.700249e-04  2.905906e-05 -1.479029e-09 -1.479029e-09  ...   \n",
      "1  1.114341e-03  4.279902e-05 -7.483097e-04 -7.255926e-04 -2.062755e-03  ...   \n",
      "2 -1.206173e-06  1.705756e-06 -4.323578e-07 -1.217126e-12 -1.206173e-06  ...   \n",
      "3 -1.183598e-11 -1.183598e-11 -1.183598e-11 -1.183273e-11 -1.183598e-11  ...   \n",
      "4 -6.799397e-04 -3.161238e-04  1.417949e-03 -1.827192e-04  6.630353e-04  ...   \n",
      "\n",
      "   feature_4502  feature_4503  feature_4504  feature_4505  feature_4506  \\\n",
      "0 -1.636430e-02 -8.329114e-03 -8.007471e-03 -1.982050e-03  6.647296e-04   \n",
      "1  6.362762e-04 -3.044075e-03 -2.151955e-03  6.359070e-04 -1.668372e-03   \n",
      "2 -9.175108e-06 -2.063779e-05  9.996018e-06 -1.313585e-05 -6.015914e-06   \n",
      "3  2.268598e-07  2.288961e-07  2.288961e-07  2.288961e-07  2.288961e-07   \n",
      "4 -7.111915e-03 -1.024937e-02 -1.243978e-02 -1.960474e-02 -8.137198e-03   \n",
      "\n",
      "   feature_4507  feature_4508  feature_4509  feature_4510  feature_4511  \n",
      "0 -1.699087e-02  1.236223e-02 -1.981586e-02 -1.256011e-02 -3.802784e-02  \n",
      "1 -1.884797e-03 -5.561413e-04 -3.433819e-03 -1.951040e-03 -2.809398e-03  \n",
      "2 -1.645591e-05 -1.015734e-05  3.493892e-06  1.914126e-05 -3.280959e-05  \n",
      "3  2.288961e-07  2.288961e-07  2.288961e-07  2.288961e-07  2.288961e-07  \n",
      "4 -8.705194e-03 -7.250022e-03 -2.497388e-02 -1.383511e-02 -1.665975e-02  \n",
      "\n",
      "[5 rows x 4512 columns]\n",
      "\n",
      "feature importance ranking\n",
      "1. feature 1552 feature_1552 (0.002533)\n",
      "2. feature 2313 feature_2313 (0.002461)\n",
      "3. feature 1355 feature_1355 (0.002240)\n",
      "4. feature 3595 feature_3595 (0.001975)\n",
      "5. feature 3422 feature_3422 (0.001663)\n",
      "6. feature 1742 feature_1742 (0.001534)\n",
      "7. feature 4473 feature_4473 (0.001524)\n",
      "8. feature 3305 feature_3305 (0.001460)\n",
      "9. feature 74 feature_74 (0.001315)\n",
      "10. feature 4097 feature_4097 (0.001314)\n",
      "11. feature 3863 feature_3863 (0.001289)\n",
      "12. feature 3982 feature_3982 (0.001279)\n",
      "13. feature 2328 feature_2328 (0.001216)\n",
      "14. feature 1731 feature_1731 (0.001198)\n",
      "15. feature 2128 feature_2128 (0.001192)\n",
      "16. feature 3359 feature_3359 (0.001188)\n",
      "17. feature 4002 feature_4002 (0.001164)\n",
      "18. feature 2016 feature_2016 (0.001133)\n",
      "19. feature 1880 feature_1880 (0.001130)\n",
      "20. feature 2172 feature_2172 (0.001119)\n",
      "21. feature 3191 feature_3191 (0.001116)\n",
      "22. feature 4363 feature_4363 (0.001101)\n",
      "23. feature 1098 feature_1098 (0.001072)\n",
      "24. feature 2710 feature_2710 (0.001053)\n",
      "25. feature 1129 feature_1129 (0.001049)\n",
      "26. feature 4288 feature_4288 (0.001046)\n",
      "27. feature 90 feature_90 (0.001027)\n",
      "28. feature 2330 feature_2330 (0.001024)\n",
      "29. feature 2274 feature_2274 (0.001023)\n",
      "30. feature 1852 feature_1852 (0.001019)\n",
      "31. feature 3031 feature_3031 (0.001018)\n",
      "32. feature 958 feature_958 (0.001011)\n",
      "33. feature 3189 feature_3189 (0.001000)\n",
      "34. feature 4092 feature_4092 (0.000997)\n",
      "35. feature 2283 feature_2283 (0.000994)\n",
      "36. feature 4250 feature_4250 (0.000994)\n",
      "37. feature 1468 feature_1468 (0.000986)\n",
      "38. feature 4256 feature_4256 (0.000982)\n",
      "39. feature 4426 feature_4426 (0.000978)\n",
      "40. feature 64 feature_64 (0.000956)\n",
      "41. feature 4121 feature_4121 (0.000945)\n",
      "42. feature 3194 feature_3194 (0.000936)\n",
      "43. feature 3195 feature_3195 (0.000915)\n",
      "44. feature 32 feature_32 (0.000913)\n",
      "45. feature 3574 feature_3574 (0.000912)\n",
      "46. feature 4120 feature_4120 (0.000910)\n",
      "47. feature 2983 feature_2983 (0.000896)\n",
      "48. feature 2308 feature_2308 (0.000895)\n",
      "49. feature 3628 feature_3628 (0.000895)\n",
      "50. feature 3109 feature_3109 (0.000894)\n",
      "(104, 50) (60, 50)\n",
      "(104, 4512)\n",
      "(60, 4512)\n",
      "(104,)\n",
      "(60,)\n",
      "      feature_0     feature_1     feature_2     feature_3     feature_4  \\\n",
      "0 -2.763211e-05 -1.479029e-09 -1.479029e-09 -1.479029e-09 -1.479029e-09   \n",
      "1 -1.027932e-03  1.454592e-04 -1.003147e-04  2.046178e-04  3.832301e-05   \n",
      "2 -8.431040e-07 -1.217126e-12 -1.217126e-12 -1.206173e-06 -1.206173e-06   \n",
      "3 -1.014059e-06 -7.238331e-06 -1.183598e-11 -1.183273e-11 -1.183128e-11   \n",
      "4  2.981465e-04 -2.129531e-09 -2.652456e-04 -4.007589e-04  6.296440e-04   \n",
      "\n",
      "      feature_5     feature_6     feature_7     feature_8     feature_9  ...  \\\n",
      "0 -1.479029e-09  1.700249e-04  2.905906e-05 -1.479029e-09 -1.479029e-09  ...   \n",
      "1  1.114341e-03  4.279902e-05 -7.483097e-04 -7.255926e-04 -2.062755e-03  ...   \n",
      "2 -1.206173e-06  1.705756e-06 -4.323578e-07 -1.217126e-12 -1.206173e-06  ...   \n",
      "3 -1.183598e-11 -1.183598e-11 -1.183598e-11 -1.183273e-11 -1.183598e-11  ...   \n",
      "4 -6.799397e-04 -3.161238e-04  1.417949e-03 -1.827192e-04  6.630353e-04  ...   \n",
      "\n",
      "   feature_4502  feature_4503  feature_4504  feature_4505  feature_4506  \\\n",
      "0 -1.636430e-02 -8.329114e-03 -8.007471e-03 -1.982050e-03  6.647296e-04   \n",
      "1  6.362762e-04 -3.044075e-03 -2.151955e-03  6.359070e-04 -1.668372e-03   \n",
      "2 -9.175108e-06 -2.063779e-05  9.996018e-06 -1.313585e-05 -6.015914e-06   \n",
      "3  2.268598e-07  2.288961e-07  2.288961e-07  2.288961e-07  2.288961e-07   \n",
      "4 -7.111915e-03 -1.024937e-02 -1.243978e-02 -1.960474e-02 -8.137198e-03   \n",
      "\n",
      "   feature_4507  feature_4508  feature_4509  feature_4510  feature_4511  \n",
      "0 -1.699087e-02  1.236223e-02 -1.981586e-02 -1.256011e-02 -3.802784e-02  \n",
      "1 -1.884797e-03 -5.561413e-04 -3.433819e-03 -1.951040e-03 -2.809398e-03  \n",
      "2 -1.645591e-05 -1.015734e-05  3.493892e-06  1.914126e-05 -3.280959e-05  \n",
      "3  2.288961e-07  2.288961e-07  2.288961e-07  2.288961e-07  2.288961e-07  \n",
      "4 -8.705194e-03 -7.250022e-03 -2.497388e-02 -1.383511e-02 -1.665975e-02  \n",
      "\n",
      "[5 rows x 4512 columns]\n",
      "\n",
      "feature importance ranking\n",
      "1. feature 2313 feature_2313 (0.003084)\n",
      "2. feature 3595 feature_3595 (0.002795)\n",
      "3. feature 3628 feature_3628 (0.002325)\n",
      "4. feature 1355 feature_1355 (0.001732)\n",
      "5. feature 3323 feature_3323 (0.001698)\n",
      "6. feature 3191 feature_3191 (0.001587)\n",
      "7. feature 1852 feature_1852 (0.001531)\n",
      "8. feature 4120 feature_4120 (0.001444)\n",
      "9. feature 2035 feature_2035 (0.001427)\n",
      "10. feature 1552 feature_1552 (0.001372)\n",
      "11. feature 4097 feature_4097 (0.001332)\n",
      "12. feature 3567 feature_3567 (0.001283)\n",
      "13. feature 2983 feature_2983 (0.001263)\n",
      "14. feature 4473 feature_4473 (0.001252)\n",
      "15. feature 3421 feature_3421 (0.001225)\n",
      "16. feature 4363 feature_4363 (0.001214)\n",
      "17. feature 1742 feature_1742 (0.001203)\n",
      "18. feature 2476 feature_2476 (0.001194)\n",
      "19. feature 3305 feature_3305 (0.001102)\n",
      "20. feature 4144 feature_4144 (0.001098)\n",
      "21. feature 4002 feature_4002 (0.001092)\n",
      "22. feature 1764 feature_1764 (0.001081)\n",
      "23. feature 2274 feature_2274 (0.001078)\n",
      "24. feature 3276 feature_3276 (0.001067)\n",
      "25. feature 3425 feature_3425 (0.001059)\n",
      "26. feature 3807 feature_3807 (0.001048)\n",
      "27. feature 4121 feature_4121 (0.001035)\n",
      "28. feature 2462 feature_2462 (0.001035)\n",
      "29. feature 2078 feature_2078 (0.001031)\n",
      "30. feature 3229 feature_3229 (0.001018)\n",
      "31. feature 2293 feature_2293 (0.001016)\n",
      "32. feature 3428 feature_3428 (0.001007)\n",
      "33. feature 4256 feature_4256 (0.001002)\n",
      "34. feature 3411 feature_3411 (0.000994)\n",
      "35. feature 3924 feature_3924 (0.000992)\n",
      "36. feature 3218 feature_3218 (0.000989)\n",
      "37. feature 3084 feature_3084 (0.000978)\n",
      "38. feature 2115 feature_2115 (0.000966)\n",
      "39. feature 1129 feature_1129 (0.000960)\n",
      "40. feature 4318 feature_4318 (0.000943)\n",
      "41. feature 74 feature_74 (0.000941)\n",
      "42. feature 3730 feature_3730 (0.000937)\n",
      "43. feature 2318 feature_2318 (0.000932)\n",
      "44. feature 3668 feature_3668 (0.000929)\n",
      "45. feature 1409 feature_1409 (0.000928)\n",
      "46. feature 2314 feature_2314 (0.000927)\n",
      "47. feature 2016 feature_2016 (0.000924)\n",
      "48. feature 951 feature_951 (0.000918)\n",
      "49. feature 3982 feature_3982 (0.000916)\n",
      "50. feature 2326 feature_2326 (0.000913)\n",
      "51. feature 3123 feature_3123 (0.000907)\n",
      "52. feature 4483 feature_4483 (0.000904)\n",
      "53. feature 3563 feature_3563 (0.000895)\n",
      "54. feature 2295 feature_2295 (0.000893)\n",
      "55. feature 3836 feature_3836 (0.000890)\n",
      "56. feature 3242 feature_3242 (0.000889)\n",
      "57. feature 4416 feature_4416 (0.000881)\n",
      "58. feature 3573 feature_3573 (0.000881)\n",
      "59. feature 2747 feature_2747 (0.000878)\n",
      "60. feature 3195 feature_3195 (0.000874)\n",
      "61. feature 1788 feature_1788 (0.000874)\n",
      "62. feature 1298 feature_1298 (0.000869)\n",
      "63. feature 3792 feature_3792 (0.000865)\n",
      "64. feature 2740 feature_2740 (0.000863)\n",
      "65. feature 2701 feature_2701 (0.000861)\n",
      "66. feature 4367 feature_4367 (0.000857)\n",
      "67. feature 4092 feature_4092 (0.000857)\n",
      "68. feature 3109 feature_3109 (0.000851)\n",
      "69. feature 2574 feature_2574 (0.000845)\n",
      "70. feature 2128 feature_2128 (0.000837)\n",
      "71. feature 88 feature_88 (0.000834)\n",
      "72. feature 2304 feature_2304 (0.000828)\n",
      "73. feature 3862 feature_3862 (0.000827)\n",
      "74. feature 1900 feature_1900 (0.000825)\n",
      "75. feature 4378 feature_4378 (0.000821)\n",
      "76. feature 1880 feature_1880 (0.000820)\n",
      "77. feature 1098 feature_1098 (0.000819)\n",
      "78. feature 4057 feature_4057 (0.000817)\n",
      "79. feature 1655 feature_1655 (0.000805)\n",
      "80. feature 4052 feature_4052 (0.000805)\n",
      "81. feature 3015 feature_3015 (0.000800)\n",
      "82. feature 83 feature_83 (0.000796)\n",
      "83. feature 1002 feature_1002 (0.000796)\n",
      "84. feature 4102 feature_4102 (0.000795)\n",
      "85. feature 1760 feature_1760 (0.000789)\n",
      "86. feature 3014 feature_3014 (0.000779)\n",
      "87. feature 30 feature_30 (0.000776)\n",
      "88. feature 4151 feature_4151 (0.000772)\n",
      "89. feature 3993 feature_3993 (0.000766)\n",
      "90. feature 4428 feature_4428 (0.000763)\n",
      "91. feature 3921 feature_3921 (0.000750)\n",
      "92. feature 1897 feature_1897 (0.000746)\n",
      "93. feature 1904 feature_1904 (0.000743)\n",
      "94. feature 3917 feature_3917 (0.000738)\n",
      "95. feature 4110 feature_4110 (0.000736)\n",
      "96. feature 461 feature_461 (0.000735)\n",
      "97. feature 1972 feature_1972 (0.000735)\n",
      "98. feature 3696 feature_3696 (0.000735)\n",
      "99. feature 3107 feature_3107 (0.000729)\n",
      "100. feature 3108 feature_3108 (0.000728)\n",
      "(104, 100) (60, 100)\n"
     ]
    }
   ],
   "source": [
    "#feature selection\n",
    "kernels = [16, 32]\n",
    "feat_numbers = [50, 100]\n",
    "\n",
    "for kernel in kernels:\n",
    "    for feat_number in feat_numbers:\n",
    "        save_dir = '../FINAL_RESULTS_60'\n",
    "        save_dir = save_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)+'/fisherVectors'\n",
    "\n",
    "        X_train = np.load(os.path.join(save_dir, 'fisher_vector_train_%i.npy' %kernel))\n",
    "        X_dev = np.load(os.path.join(save_dir, 'fisher_vector_dev_%i.npy' %kernel))\n",
    "        y_train = np.load(os.path.join(save_dir, 'session_label_train.npy'))\n",
    "        y_dev = np.load(os.path.join(save_dir, 'session_label_dev.npy'))\n",
    "\n",
    "        print (X_train.shape)\n",
    "        print (X_dev.shape)\n",
    "        print (y_train.shape)\n",
    "        print (y_dev.shape)\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=800, criterion='entropy')\n",
    "        df = pd.DataFrame(np.vstack((X_train, X_dev)))\n",
    "        feature_names = ['feature_%d' % i for i in range(len(X_train[0]))]\n",
    "        df.columns = feature_names\n",
    "        y = np.hstack((y_train, y_dev))\n",
    "        print(df.head())\n",
    "\n",
    "        model.fit(df, y)\n",
    "        importances = model.feature_importances_\n",
    "        print(\"\\nfeature importance ranking\")\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        for f in range(feat_number):\n",
    "            print(\"%d. feature %d %s (%f)\" % (f+1, indices[f], feature_names[indices[f]], importances[indices[f]]))\n",
    "        indices = indices[:feat_number]\n",
    "\n",
    "        X_train_df = pd.DataFrame(X_train)\n",
    "        X_train_df.columns = ['feature_%d' % i for i in range(len(X_train[0]))]\n",
    "        X_train_tree = X_train_df.iloc[:, indices]\n",
    "\n",
    "        X_dev_df = pd.DataFrame(X_dev)\n",
    "        X_dev_df.columns = ['feature_%d' % i for i in range(len(X_dev[0]))]\n",
    "        X_dev_tree = X_dev_df.iloc[:, indices]\n",
    "\n",
    "        print(X_train_tree.shape, X_dev_tree.shape)\n",
    "\n",
    "        save_dir = '../FINAL_RESULTS_60'\n",
    "        save_dir = save_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)\n",
    "\n",
    "        np.save(os.path.join(save_dir, 'X_train_tree_%i_%i' %(kernel, feat_number)), X_train_tree)\n",
    "        np.save(os.path.join(save_dir, 'X_dev_tree_%i_%i' %(kernel, feat_number)), X_dev_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestCV():\n",
    "   \n",
    "    def __init__(self, feature_name, X_train, y_train, X_dev, y_dev, line):\n",
    "        self.config = json.load(open('../model.json', 'r'))\n",
    "        self.model_name = 'RF_CV'\n",
    "        self.feature_name = feature_name\n",
    "        self.X_train = X_train\n",
    "        self.X_dev = X_dev\n",
    "        self.y_train = y_train\n",
    "        self.y_dev = y_dev\n",
    "        self.parameters = dict()\n",
    "        self.parameters['n_estimators'] = None\n",
    "        self.parameters['max_features'] = None\n",
    "        self.parameters['max_depth'] = None\n",
    "        self.parameters['criterion'] = None\n",
    "        self.model = None\n",
    "        self.line = line\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"main function for the model\"\"\"\n",
    "        filename = os.path.join(self.line, '%s_%s_params.json' % (self.model_name, self.feature_name))\n",
    "\n",
    "        if os.path.isfile(filename):\n",
    "            self.parameters = json.load(open(filename, 'r'))\n",
    "        \n",
    "        if not self.parameters['n_estimators'] or not self.parameters['max_features'] or not self.parameters['max_depth'] or not self.parameters['criterion']:\n",
    "            print(\"\\nhyperparameters are not tuned yet\")\n",
    "            self.crossvalidate()\n",
    "        else:\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=self.parameters['n_estimators'], \n",
    "                max_features=self.parameters['max_features'], \n",
    "                max_depth=self.parameters['max_depth'], \n",
    "                criterion=self.parameters['criterion'], \n",
    "                verbose=1, n_jobs=-1,\n",
    "                class_weight=\"balanced\")\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            y_pred_train = self.model.predict(self.X_train)\n",
    "            y_pred_dev = self.model.predict(self.X_dev)\n",
    "            \n",
    "            precision, recall, fscore, _ = precision_recall_fscore_support(self.y_dev, y_pred_dev, average='macro')\n",
    "\n",
    "            print(\"\\naccuracy on training set: %.4f\" % metrics.accuracy_score(y_pred_train, self.y_train))\n",
    "            print(\"\\naccuracy on development set: %.4f\" % metrics.accuracy_score(y_pred_dev, self.y_dev))\n",
    "            print(\"\\nprecision on dev set: %.4f\" % precision)\n",
    "            print(\"\\nrecall on dev set: %.4f\" % recall)\n",
    "            print(\"\\nfscore on dev set: %.4f\" % fscore)\n",
    "        \n",
    "            \n",
    "    def crossvalidate(self):\n",
    "        \n",
    "        parameters = {\n",
    "            \"n_estimators\": self.config['baseline']['random_forest']['n_estimators'],\n",
    "            \"max_features\": self.config['baseline']['random_forest']['max_features'],\n",
    "            \"max_depth\": self.config['baseline']['random_forest']['max_depth'],\n",
    "            \"criterion\": [\"entropy\"]\n",
    "        }\n",
    "        \n",
    "        print(\"\\nrunning the Grid Search for Random Forest CV classifier ...\")\n",
    "        clf = GridSearchCV(RandomForestClassifier(), \n",
    "                        parameters, \n",
    "                        cv=5, \n",
    "                        n_jobs=-1, \n",
    "                        verbose=3, \n",
    "                        scoring='recall_macro')\n",
    "        \n",
    "        clf.fit(self.X_train, self.y_train)\n",
    "        print(\"\\nfinal score for the tuned model\\n\", clf.score(self.X_dev, self.y_dev))\n",
    "        print(\"\\nbest hyperparameters for the tuned model\\n\", clf.best_params_)\n",
    "        print(\"\\ncross validation results (MEAN)\\n\", clf.cv_results_['mean_test_score'])\n",
    "        print(\"\\ncross validation results (STD)\\n\", clf.cv_results_['std_test_score'])\n",
    "\n",
    "        self.parameters['n_estimators'] = clf.best_params_['n_estimators']\n",
    "        self.parameters['max_features'] = clf.best_params_['max_features']\n",
    "        self.parameters['max_depth'] = clf.best_params_['max_depth']\n",
    "        self.parameters['criterion'] = clf.best_params_['criterion']\n",
    "        \n",
    "        filename = os.path.join(self.line, '%s_%s_params.json' % (self.model_name, self.feature_name))\n",
    "        \n",
    "        # write to model json file\n",
    "        with open(filename, 'w') as output:\n",
    "            json.dump(self.parameters, output)\n",
    "            output.write(\"\\n\")\n",
    "        output.close()\n",
    "        \n",
    "        best_grid = clf.best_estimator_\n",
    "        print(\"\\nevaluating the Random Forest Classifier ...\")\n",
    "        y_pred_train = best_grid.predict(self.X_train)\n",
    "        y_pred_dev = best_grid.predict(self.X_dev)\n",
    "        \n",
    "        precision, recall, fscore, _ = precision_recall_fscore_support(self.y_dev, y_pred_dev, average='macro')\n",
    "        \n",
    "        filename = os.path.join(self.line, '%s_%s_score.json' % (self.model_name, self.feature_name))\n",
    "        file = open(filename,\"w\") \n",
    "        file.write(\"\\nprecision on dev set: %.4f\" % precision) \n",
    "        file.write(\"\\nrecall on dev set: %.4f\" % recall) \n",
    "        file.write(\"\\nfscore on dev set: %.4f\" % fscore) \n",
    "        file.write(\"\\naccuracy on dev set: %.4f\" % metrics.accuracy_score(y_pred_dev, y_dev)) \n",
    "        file.close() \n",
    "\n",
    "        print(\"\\naccuracy on training set: %.4f\" % metrics.accuracy_score(y_pred_train, self.y_train))\n",
    "        print(\"\\naccuracy on development set: %.4f\" % metrics.accuracy_score(y_pred_dev, self.y_dev))\n",
    "        print(\"\\nprecision on dev set: %.4f\" % precision)\n",
    "        print(\"\\nrecall on dev set: %.4f\" % recall)\n",
    "        print(\"\\nfscore on dev set: %.4f\" % fscore)\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running Random Forest with Cross Validation on Fisher Vectors\n",
      "Kernels 16 and features number 50\n",
      "(104, 50)\n",
      "(60, 50)\n",
      "(104,)\n",
      "(60,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='../model.json' mode='r' encoding='UTF-8'>\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: ResourceWarning: unclosed file <_io.TextIOWrapper name='../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/RF_CV_MFCC_16_50_params.json' mode='r' encoding='UTF-8'>\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='../model.json' mode='r' encoding='UTF-8'>\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: ResourceWarning: unclosed file <_io.TextIOWrapper name='../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/RF_CV_MFCC_16_100_params.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy on training set: 0.9231\n",
      "\n",
      "accuracy on development set: 0.5167\n",
      "\n",
      "precision on dev set: 0.5238\n",
      "\n",
      "recall on dev set: 0.5238\n",
      "\n",
      "fscore on dev set: 0.5238\n",
      "------------------------------------------------------------\n",
      "Kernels 16 and features number 100\n",
      "(104, 100)\n",
      "(60, 100)\n",
      "(104,)\n",
      "(60,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 out of 100 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=80)]: Done  42 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='../model.json' mode='r' encoding='UTF-8'>\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: ResourceWarning: unclosed file <_io.TextIOWrapper name='../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/RF_CV_MFCC_32_50_params.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy on training set: 1.0000\n",
      "\n",
      "accuracy on development set: 0.6167\n",
      "\n",
      "precision on dev set: 0.6140\n",
      "\n",
      "recall on dev set: 0.6243\n",
      "\n",
      "fscore on dev set: 0.6157\n",
      "------------------------------------------------------------\n",
      "Kernels 32 and features number 50\n",
      "(104, 50)\n",
      "(60, 50)\n",
      "(104,)\n",
      "(60,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: ResourceWarning: unclosed file <_io.TextIOWrapper name='../model.json' mode='r' encoding='UTF-8'>\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: ResourceWarning: unclosed file <_io.TextIOWrapper name='../FINAL_RESULTS_60/MFCC_timesteps60_dimensionsBiLstm35/RF_CV_MFCC_32_100_params.json' mode='r' encoding='UTF-8'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy on training set: 1.0000\n",
      "\n",
      "accuracy on development set: 0.7000\n",
      "\n",
      "precision on dev set: 0.6964\n",
      "\n",
      "recall on dev set: 0.7063\n",
      "\n",
      "fscore on dev set: 0.6934\n",
      "------------------------------------------------------------\n",
      "Kernels 32 and features number 100\n",
      "(104, 100)\n",
      "(60, 100)\n",
      "(104,)\n",
      "(60,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy on training set: 1.0000\n",
      "\n",
      "accuracy on development set: 0.7833\n",
      "\n",
      "precision on dev set: 0.7873\n",
      "\n",
      "recall on dev set: 0.7857\n",
      "\n",
      "fscore on dev set: 0.7854\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=80)]: Done 200 out of 200 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=80)]: Done  40 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=80)]: Done 200 out of 200 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nrunning Random Forest with Cross Validation on Fisher Vectors\")\n",
    "\n",
    "kernels = [16, 32]\n",
    "feat_numbers = [50, 100]\n",
    "feature_type = 'MFCC'\n",
    "\n",
    "for kernel in kernels:\n",
    "    for feat_number in feat_numbers:\n",
    "        print ('Kernels %i and features number %i' %(kernel, feat_number))\n",
    "\n",
    "        save_dir = '../FINAL_RESULTS_60'\n",
    "        save_dir = save_dir + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)\n",
    "\n",
    "        X_train = np.load(os.path.join(save_dir, 'X_train_tree_%i_%i.npy' %(kernel, feat_number)))\n",
    "        X_dev = np.load(os.path.join(save_dir, 'X_dev_tree_%i_%i.npy' %(kernel, feat_number)))\n",
    "\n",
    "        label_path = '../FINAL_RESULTS_60'\n",
    "        label_path = label_path + '/'+feature_type+'_timesteps'+str(timesteps)+'_dimensionsBiLstm'+str(dimensions_lstm)+'/fisherVectors/'\n",
    "        y_train = np.load(os.path.join(label_path, 'session_label_train.npy'))\n",
    "        y_dev = np.load(os.path.join(label_path, 'session_label_dev.npy'))\n",
    "\n",
    "        print (X_train.shape)\n",
    "        print (X_dev.shape)\n",
    "        print (y_train.shape)\n",
    "        print (y_dev.shape)\n",
    "        \n",
    "        feature_name = 'MFCC'\n",
    "        feature_name = feature_name +'_'+str(kernel)+'_'+str(feat_number) \n",
    "        random_forest = RandomForestCV(feature_name, X_train, y_train, X_dev, y_dev, save_dir)\n",
    "        random_forest.run()\n",
    "        print (\"------\"  * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
