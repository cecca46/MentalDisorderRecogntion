{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used to preprocess the input modalities and make them suitable for the developed framework on the Bipolar Disorder Corpus. The audio-visual modalities are aligned and written into correspoding files. One file is created for MFCC and one for eGeMAPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import traceback\n",
    "import statistics\n",
    "from scipy.io import arff\n",
    "from collections import Counter\n",
    "from smart_open import smart_open\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from collections import Counter\n",
    "from smart_open import smart_open\n",
    "matplotlib.use('GTK')\n",
    "\n",
    "def get_sample(partition, index):\n",
    "    if index < 0:\n",
    "        return\n",
    "    sample_name = ''\n",
    "    if partition == 'train':\n",
    "        if index > 104:\n",
    "            print(\"ERROR\")\n",
    "        else:\n",
    "            sample_name = 'train_' + str(index).zfill(3)\n",
    "    elif partition == 'dev':\n",
    "        if index > 60:\n",
    "            print(\"ERROR\")\n",
    "        else:\n",
    "            sample_name = 'dev_' + str(index).zfill(3)\n",
    "    elif partition == 'test':\n",
    "        if index > 54:\n",
    "            print(\"ERROR\")\n",
    "        else:\n",
    "            sample_name = 'test_' + str(index).zfill(3)\n",
    "    else:\n",
    "        print(\"INCORRECT PARTITION INPUT\")\n",
    "    return sample_name\n",
    "\n",
    "#only select relevant features\n",
    "def preprocess_AU():\n",
    "    verbose = True\n",
    "    raw_dir = \"/home/ceccarelli/Work/Bipolar/LLDs_video_openface\"\n",
    "    proc_dir = \"/home/ceccarelli/Work/Bipolar/LLDs_video_openface_processed\"\n",
    "    length = dict()\n",
    "    length['train'] = 104\n",
    "    length['dev'] = 60\n",
    "    length['test'] = 54\n",
    "\n",
    "    time = ['timestamp']\n",
    "    landmarks = ['%s_%d' % (xy, i) for xy in ['x', 'y'] for i in range(68)]\n",
    "    gazes = ['gaze_%d_%s' % (no, di) for no in range(2) for di in ['x', 'y', 'z']]\n",
    "    poses = ['pose_%s' % xyz for xyz in ['Tx', 'Ty', 'Tz', 'Rx', 'Ry', 'Rz']]\n",
    "    actions = ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r',\n",
    "               'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r',\n",
    "               'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r', 'AU01_c',\n",
    "               'AU02_c', 'AU04_c', 'AU05_c', 'AU06_c', 'AU07_c', 'AU09_c',\n",
    "               'AU10_c', 'AU12_c', 'AU14_c', 'AU15_c', 'AU17_c', 'AU20_c',\n",
    "               'AU23_c', 'AU25_c', 'AU26_c', 'AU28_c', 'AU45_c']\n",
    "\n",
    "    visual = time\n",
    "    visual.extend(landmarks)\n",
    "    visual.extend(gazes)\n",
    "    visual.extend(poses)\n",
    "    visual.extend(actions)\n",
    "\n",
    "    if verbose:\n",
    "        print(time)\n",
    "        print(landmarks)\n",
    "        print(gazes)\n",
    "        print(poses)\n",
    "        print(actions)\n",
    "\n",
    "    for partition in ['train', 'dev', 'test']:\n",
    "        for i in range(length[partition]):\n",
    "            filename = get_sample(partition, (i+1))\n",
    "            temp = pd.read_csv(os.path.join(raw_dir, filename + '.csv'))\n",
    "            temp.columns = temp.columns.str.strip()\n",
    "            print(\"file %s loaded\" % filename)\n",
    "            # select specified columns\n",
    "            temp = temp.loc[:, visual]\n",
    "            temp.to_csv(os.path.join(proc_dir, filename + '.csv'), index=False)\n",
    "            print(\"file %s processing completed & saved\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done it once\n",
    "preprocess_AU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align auudio and video data\n",
    "def align(eGeMAPS=False, verbose=False):\n",
    "\n",
    "    input_dir_A = '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile/LLDs_audio_opensmile_MFCCs' if not eGeMAPS else '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile/LLDs_audio_eGeMAPS'\n",
    "    input_dir_V = '/home/ceccarelli/Work/Bipolar/LLDs_video_openface_processed'\n",
    "    output_dir_A = '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile_aligned/MFCCs' if not eGeMAPS else '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile_aligned/eGeMAPS'\n",
    "    length = dict()\n",
    "    length['train'] = 104\n",
    "    length['dev'] = 60\n",
    "    length['test'] = 54\n",
    "\n",
    "    for partition in ['train', 'dev', 'test']:\n",
    "        for i in range(length[partition]):\n",
    "            filename = get_sample(partition, (i+1)) + '.csv'\n",
    "\n",
    "            if verbose:\n",
    "                print(\"file %s loaded.\" % filename)\n",
    "\n",
    "            temp_A = pd.read_csv(os.path.join(input_dir_A, filename), sep=';', index_col=1)\n",
    "            temp_A.drop(\"name\", axis=1, inplace=True)\n",
    "            del temp_A.index.name\n",
    "            temp_V = pd.read_csv(os.path.join(input_dir_V, filename))\n",
    "            align_A = pd.DataFrame(np.zeros((len(temp_V), temp_A.shape[1]*3)))\n",
    "            align_A.index = temp_V.loc[:, 'timestamp']\n",
    "            del align_A.index.name\n",
    "\n",
    "            A_list = temp_A.index.tolist()\n",
    "            V_list = temp_V.loc[:, 'timestamp'].tolist()\n",
    "\n",
    "            for j in range(len(V_list) - 1):\n",
    "                a_list = []\n",
    "                for a in A_list:\n",
    "                    if a > V_list[j] and a < V_list[j+1]:\n",
    "                        a_list.append(a)\n",
    "                if len(a_list) == 1:\n",
    "                    a_list *= 3\n",
    "                elif len(a_list) == 2:\n",
    "                    a_list.append(a_list[1])\n",
    "                elif len(a_list) == 3:\n",
    "                    a_list = a_list\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                assert len(a_list) == 3\n",
    "\n",
    "                align_A.loc[V_list[j], :] = pd.concat([\n",
    "                    temp_A.loc[a_list[0]],\n",
    "                    temp_A.loc[a_list[1]],\n",
    "                    temp_A.loc[a_list[2]]],\n",
    "                    axis=0, sort=False, ignore_index=True)\n",
    "\n",
    "            align_A.to_csv(os.path.join(output_dir_A, filename))\n",
    "\n",
    "            if verbose:\n",
    "                print(\"file %s processed & saved.\" % filename)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for both kind of audio modalities \n",
    "align(True)\n",
    "#align(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(partition=True, verbose=True):\n",
    "    \n",
    "    label = pd.read_csv(\"/home/ceccarelli/Work/Bipolar/labels_metadata.csv\")\n",
    "    id_list = label['SubjectID'].tolist()\n",
    "\n",
    "    id_set = set()\n",
    "    age_list = list()\n",
    "    for id in id_list:\n",
    "        id_set.add(id)\n",
    "        age_list.extend(label[label.SubjectID == id]['Age'].tolist())\n",
    "\n",
    "    gender_list = list()\n",
    "    for sub in id_set:\n",
    "        gender_list.append(sub[:1])\n",
    "        if verbose:\n",
    "            print(\"%s subject have %d instances\" % (sub, id_list.count(sub)))\n",
    "\n",
    "    classes_stats = Counter(label['ManiaLevel'].tolist())\n",
    "\n",
    "    if verbose:\n",
    "        print(\"All subjects\", len(id_set))\n",
    "        print(\"Male subjects \", gender_list.count('M'))\n",
    "        print(\"Female subjects\", gender_list.count('F'))\n",
    "        print(\"Age range (%d, %d), Age median %d\" % (min(age_list), max(age_list), statistics.median(age_list)))\n",
    "        print(\"Class distribution stats\", classes_stats)\n",
    "\n",
    "    ymrs_score = pd.concat([label.iloc[:, 0], label.iloc[:, 4]], axis=1)\n",
    "    mania_level = pd.concat([label.iloc[:, 0], label.iloc[:, 5]], axis=1)\n",
    "    if partition:\n",
    "        ymrs_dev = ymrs_score.iloc[:60, :]\n",
    "        ymrs_train = ymrs_score.iloc[60:, :]\n",
    "        level_dev = mania_level.iloc[:60, :]\n",
    "        level_train = mania_level.iloc[60:, :]\n",
    "        return ymrs_dev.values[:, 1], ymrs_train.values[:, 1], level_dev.values[:, 1], level_train.values[:, 1]\n",
    "    else:\n",
    "        return ymrs_score, mania_level, 0, 0\n",
    "\n",
    "def write_features(no_data=False, eGeMAPS=False, verbose=False):\n",
    "    \"\"\"load preprocessed visual and acoustic features\n",
    "    \"\"\"\n",
    "\n",
    "    visual_dir = '/home/ceccarelli/Work/Bipolar/LLDs_video_openface_processed'\n",
    "    acoustic_dir = '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile_aligned/MFCCs' if not eGeMAPS else '/home/ceccarelli/Work/Bipolar/LLDs_audio_opensmile_aligned/eGeMAPS'\n",
    "    output_dir = '/home/ceccarelli/Work/Bipolar/aligned_AV' if not eGeMAPS else '/home/ceccarelli/Work/Bipolar/aligned_EAV' \n",
    "\n",
    "    if no_data:\n",
    "        print (\"This will only load labels later.\")\n",
    "    else:\n",
    "        length = dict()\n",
    "        length['train'] = 104\n",
    "        length['dev'] = 60\n",
    "        length['test'] = 54\n",
    "\n",
    "        _, _, level_dev, level_train = load_label()\n",
    "        label_train, label_dev = level_train, level_dev\n",
    "        labels = dict()\n",
    "        labels['train'] = label_train\n",
    "        labels['dev'] = label_dev\n",
    "\n",
    "        dimensionality = dict()\n",
    "        dimensionality['train'] = 0\n",
    "        dimensionality['dev'] = 0\n",
    "\n",
    "        for partition in ['train', 'dev']:\n",
    "            s1 = output_dir+'/'+partition+'_label'\n",
    "            s2 = output_dir+'/'+partition+'_inst'\n",
    "            label_f = smart_open(s1, 'w', encoding='utf-8')\n",
    "            inst_f = smart_open(s2, 'w', encoding='utf-8')\n",
    "            A_data, V_data = None, None\n",
    "            label = labels[partition]\n",
    "\n",
    "            for i in range(length[partition]):\n",
    "                filename = get_sample(partition, (i+1)) + '.csv'\n",
    "                A_feature = pd.read_csv(os.path.join(acoustic_dir, filename), low_memory=False)\n",
    "                V_feature = pd.read_csv(os.path.join(visual_dir, filename), low_memory=False)\n",
    "                A_t, _ = A_feature.shape\n",
    "                V_t, _ = V_feature.shape\n",
    "                print ('A shape is', A_t)\n",
    "                print ('V shape is', V_t)\n",
    "                assert A_t == V_t\n",
    "                timestep = A_t\n",
    "                dimensionality[partition] += timestep\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"file %s loaded with timestep %d\" % (filename, timestep), A_feature.shape, V_feature.shape)\n",
    "\n",
    "                # concatenate features\n",
    "                A_data = A_feature.copy() if not i else pd.concat([A_data, A_feature])\n",
    "                V_data = V_feature.copy() if not i else pd.concat([V_data, V_feature])\n",
    "                # write labels and instances\n",
    "                l = str(label[i])+','\n",
    "                p = str(i+1)+','\n",
    "                label_f.write(l * timestep)\n",
    "                inst_f.write(p * timestep)\n",
    "            s3 = output_dir+'/'+partition+'_data_A'\n",
    "            s4 = output_dir+'/'+partition+'_data_V'\n",
    "            A_data.to_csv(s3, header=False, index=False)\n",
    "            V_data.to_csv(s4, header=False, index=False)\n",
    "            label_f.close()\n",
    "            inst_f.close()\n",
    "            print(\"partition %s done.\" % partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for the different audio modalities\n",
    "write_features(eGeMAPS=True)\n",
    "#write_features(eGeMAPS=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
