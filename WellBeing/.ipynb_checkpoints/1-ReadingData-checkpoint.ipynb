{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the patient files for the Well-Being dataset in the format useful for the proposed framework. It also computes the serialised version of the data and the dynamic changes of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from os import listdir\n",
    "import os \n",
    "from os.path import isfile, join\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"full_fused_data\"\n",
    "DATA_PATH2 = \"processed_data_smooth\"\n",
    "DATA_PATH3 = \"all_video_audio\"\n",
    "DATA_PATH4 = \"AllData\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "partecipants_data = dict()\n",
    "for i in range(len(onlyfiles)):\n",
    "    tmp = onlyfiles[i].split(\"_\")\n",
    "    partecipants_ids = tmp[2].split(\".\")[0]\n",
    "    for j in range(len(onlyfiles)):\n",
    "        partecipants_files = list()\n",
    "        tmp2 = onlyfiles[j].split(\"_\")\n",
    "        tmp3 = tmp2[2].split(\".\")[0]\n",
    "        if (tmp3 == partecipants_ids):\n",
    "            if (onlyfiles[j] not in partecipants_data.values()):\n",
    "                partecipants_data.setdefault(partecipants_ids, [])\n",
    "                partecipants_data[partecipants_ids].append(onlyfiles[j])\n",
    "                \n",
    "for k in partecipants_data.keys():\n",
    "    partecipants_data[k] = set(partecipants_data[k])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_label_data = {\n",
    "    13: {\n",
    "        0: [0]\n",
    "    },\n",
    "    14: {\n",
    "        0: [1]\n",
    "    },\n",
    "    15: {\n",
    "        0: [1]\n",
    "    },\n",
    "    18: {\n",
    "        0: [2]\n",
    "    },\n",
    "    20: {\n",
    "        0: [1]\n",
    "    },\n",
    "    29: {\n",
    "        0: [0],\n",
    "    },\n",
    "    33: {\n",
    "        0: [1]\n",
    "    },\n",
    "    39: {\n",
    "        0: [1],\n",
    "        1: [1],\n",
    "        2: []  # Broken\n",
    "    },\n",
    "    45: {\n",
    "        0: [1, 2],\n",
    "        1: [0, 1],\n",
    "        2: [1, 2, 3],\n",
    "        3: [0, 1],\n",
    "        4: [0, 1, 2, 3]\n",
    "    },\n",
    "    46: {\n",
    "        0: [],  # Not Speaking\n",
    "        1: [1]\n",
    "    },\n",
    "    64: {\n",
    "        0:[1, 3],\n",
    "    },\n",
    "    25: {\n",
    "        0:[1, 2],\n",
    "        1: [1]\n",
    "    },\n",
    "    50: {\n",
    "        0: [0, 2]\n",
    "    },\n",
    "    52: {\n",
    "        0: [1],\n",
    "        1: [0, 1]\n",
    "    },\n",
    "    56: {\n",
    "        0: [1],\n",
    "        1: [1]\n",
    "    },\n",
    "    58: {\n",
    "        0: [1]\n",
    "    },\n",
    "    59: {\n",
    "        0: [1],\n",
    "        1: [1],\n",
    "        2: [1],\n",
    "        3: [2],\n",
    "        4: [1, 3]\n",
    "    },\n",
    "    61: {\n",
    "        0: [0]\n",
    "    },\n",
    "    65: {\n",
    "        0: [0],\n",
    "        1: [0, 1],\n",
    "    },\n",
    "    70: {\n",
    "        0: [1],\n",
    "        1: [1],\n",
    "    },\n",
    "    73: {\n",
    "        0: [0, 2, 3],\n",
    "        1: [0, 2, 3],\n",
    "        2: [2],\n",
    "        3: [1, 3],\n",
    "        4: [3],\n",
    "    },\n",
    "    74: {\n",
    "        0: [1, 2],\n",
    "        1: [1, 2],\n",
    "    },\n",
    "    76: {\n",
    "        0: [1],\n",
    "        1: [0],\n",
    "        2: [1],\n",
    "    },\n",
    "    86: {\n",
    "        0: [2],\n",
    "        1: [1],\n",
    "    },\n",
    "    87:{\n",
    "        0: [1, 2, 3],\n",
    "    },\n",
    "    88:{\n",
    "        0: [1],\n",
    "    },\n",
    "    89: {\n",
    "        0: [1],\n",
    "    },\n",
    "    90: {\n",
    "        0: [1],\n",
    "        1: [0, 1, 3],\n",
    "    },\n",
    "    91: {\n",
    "        0: [0, 2],\n",
    "    },\n",
    "    94: {\n",
    "        0: [0, 1, 4],\n",
    "    },\n",
    "    100: {\n",
    "        0: [0],\n",
    "        1: [0],\n",
    "        2: [0],\n",
    "        3: [3],\n",
    "    },\n",
    "    102: {\n",
    "        0: [1],\n",
    "    },\n",
    "    105: {\n",
    "        0: [2],\n",
    "        1: [1],\n",
    "        2: [2],\n",
    "    },\n",
    "    112: {\n",
    "        0: [1],\n",
    "    }\n",
    "}        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14782, 65)\n",
      "(14782, 66)\n",
      "AllData/participant_video_56_1.npy\n",
      "(1377, 65)\n",
      "(1377, 66)\n",
      "AllData/participant_video_56_0.npy\n",
      "(20871, 65)\n",
      "(20871, 66)\n",
      "AllData/participant_video_102.npy\n",
      "(10730, 65)\n",
      "(10730, 66)\n",
      "AllData/participant_video_76_1.npy\n",
      "(7604, 65)\n",
      "(7604, 66)\n",
      "AllData/participant_video_76_2.npy\n",
      "(3244, 65)\n",
      "(3244, 66)\n",
      "AllData/participant_video_76_0.npy\n",
      "(22107, 65)\n",
      "(22107, 66)\n",
      "AllData/participant_video_112.npy\n",
      "(21847, 65)\n",
      "(21847, 66)\n",
      "AllData/participant_video_52_0.npy\n",
      "(3338, 65)\n",
      "(3338, 66)\n",
      "AllData/participant_video_52_1.npy\n",
      "(22363, 65)\n",
      "(22363, 66)\n",
      "AllData/participant_video_74_0.npy\n",
      "(5082, 65)\n",
      "(5082, 66)\n",
      "AllData/participant_video_74_1.npy\n",
      "(30340, 65)\n",
      "(30340, 66)\n",
      "AllData/participant_video_50.npy\n",
      "(20736, 65)\n",
      "(20736, 66)\n",
      "AllData/participant_video_91.npy\n",
      "(554, 65)\n",
      "(554, 66)\n",
      "AllData/participant_video_46_0.npy\n",
      "(20800, 65)\n",
      "(20800, 66)\n",
      "AllData/participant_video_46_1.npy\n",
      "(2115, 65)\n",
      "(2115, 66)\n",
      "AllData/participant_video_86_1.npy\n",
      "(8872, 65)\n",
      "(8872, 66)\n",
      "AllData/participant_video_86_0.npy\n",
      "(4726, 65)\n",
      "(4726, 66)\n",
      "AllData/participant_video_25_0.npy\n",
      "(15740, 65)\n",
      "(15740, 66)\n",
      "AllData/participant_video_25_1.npy\n",
      "(7527, 65)\n",
      "(7527, 66)\n",
      "AllData/participant_video_59_1.npy\n",
      "(1189, 65)\n",
      "(1189, 66)\n",
      "AllData/participant_video_59_4.npy\n",
      "(6240, 65)\n",
      "(6240, 66)\n",
      "AllData/participant_video_59_2.npy\n",
      "(795, 65)\n",
      "(795, 66)\n",
      "AllData/participant_video_59_3.npy\n",
      "(8275, 65)\n",
      "(8275, 66)\n",
      "AllData/participant_video_59_0.npy\n",
      "(9082, 65)\n",
      "(9082, 66)\n",
      "AllData/participant_video_45_2.npy\n",
      "(1748, 65)\n",
      "(1748, 66)\n",
      "AllData/participant_video_45_1.npy\n",
      "(13717, 65)\n",
      "(13717, 66)\n",
      "AllData/participant_video_45_4.npy\n",
      "(6947, 65)\n",
      "(6947, 66)\n",
      "AllData/participant_video_45_3.npy\n",
      "(1641, 65)\n",
      "(1641, 66)\n",
      "AllData/participant_video_45_0.npy\n",
      "(6088, 65)\n",
      "(6088, 66)\n",
      "AllData/participant_video_39_0.npy\n",
      "(525, 65)\n",
      "(525, 66)\n",
      "AllData/participant_video_39_2.npy\n",
      "(6160, 65)\n",
      "(6160, 66)\n",
      "AllData/participant_video_39_1.npy\n",
      "(12377, 65)\n",
      "(12377, 66)\n",
      "AllData/participant_video_70_1.npy\n",
      "(9620, 65)\n",
      "(9620, 66)\n",
      "AllData/participant_video_70_0.npy\n",
      "(16824, 65)\n",
      "(16824, 66)\n",
      "AllData/participant_video_33.npy\n",
      "(1630, 65)\n",
      "(1630, 66)\n",
      "AllData/participant_video_73_4.npy\n",
      "(5003, 65)\n",
      "(5003, 66)\n",
      "AllData/participant_video_73_0.npy\n",
      "(1761, 65)\n",
      "(1761, 66)\n",
      "AllData/participant_video_73_1.npy\n",
      "(331, 65)\n",
      "(331, 66)\n",
      "AllData/participant_video_73_2.npy\n",
      "(6543, 65)\n",
      "(6543, 66)\n",
      "AllData/participant_video_73_3.npy\n",
      "(11936, 65)\n",
      "(11936, 66)\n",
      "AllData/participant_video_105_0.npy\n",
      "(3767, 65)\n",
      "(3767, 66)\n",
      "AllData/participant_video_105_2.npy\n",
      "(540, 65)\n",
      "(540, 66)\n",
      "AllData/participant_video_105_1.npy\n",
      "(15124, 65)\n",
      "(15124, 66)\n",
      "AllData/participant_video_64.npy\n",
      "(17507, 65)\n",
      "(17507, 66)\n",
      "AllData/participant_video_58.npy\n",
      "(19726, 65)\n",
      "(19726, 66)\n",
      "AllData/participant_video_89.npy\n",
      "(24878, 65)\n",
      "(24878, 66)\n",
      "AllData/participant_video_15.npy\n",
      "(12136, 65)\n",
      "(12136, 66)\n",
      "AllData/participant_video_65_0.npy\n",
      "(2836, 65)\n",
      "(2836, 66)\n",
      "AllData/participant_video_65_1.npy\n",
      "(27486, 65)\n",
      "(27486, 66)\n",
      "AllData/participant_video_18.npy\n",
      "(21645, 65)\n",
      "(21645, 66)\n",
      "AllData/participant_video_90_1.npy\n",
      "(2421, 65)\n",
      "(2421, 66)\n",
      "AllData/participant_video_90_0.npy\n",
      "(26646, 65)\n",
      "(26646, 66)\n",
      "AllData/participant_video_94.npy\n",
      "(26586, 65)\n",
      "(26586, 66)\n",
      "AllData/participant_video_88.npy\n",
      "(21995, 65)\n",
      "(21995, 66)\n",
      "AllData/participant_video_61.npy\n",
      "(13844, 65)\n",
      "(13844, 66)\n",
      "AllData/participant_video_29.npy\n",
      "(3763, 65)\n",
      "(3763, 66)\n",
      "AllData/participant_video_100_1.npy\n",
      "(1818, 65)\n",
      "(1818, 66)\n",
      "AllData/participant_video_100_2.npy\n",
      "(12925, 65)\n",
      "(12925, 66)\n",
      "AllData/participant_video_100_3.npy\n",
      "(1536, 65)\n",
      "(1536, 66)\n",
      "AllData/participant_video_100_0.npy\n",
      "(19701, 65)\n",
      "(19701, 66)\n",
      "AllData/participant_video_20.npy\n",
      "(16212, 65)\n",
      "(16212, 66)\n",
      "AllData/participant_video_87.npy\n",
      "(31074, 65)\n",
      "(31074, 66)\n",
      "AllData/participant_video_14.npy\n",
      "(16653, 65)\n",
      "(16653, 66)\n",
      "AllData/participant_video_13.npy\n"
     ]
    }
   ],
   "source": [
    "for participant_id in partecipants_data.keys():\n",
    "    if participant_id in [109]:\n",
    "        continue\n",
    "    if int(participant_id) > 200:\n",
    "        continue\n",
    "    for session_id in partecipants_data[participant_id]:\n",
    "        tmp = session_id.split(\"_\")\n",
    "        if (len(tmp)==4):\n",
    "            ids = tmp[2]\n",
    "            sess = tmp[3].split(\".\")[0]\n",
    "        else:\n",
    "            sess = 0\n",
    "            ids = tmp[2].split(\".\")[0]\n",
    "            \n",
    "        \n",
    "        fused_data_path = os.path.join(DATA_PATH, session_id)\n",
    "        fused_data = pickle.load(open(fused_data_path, 'rb'))\n",
    "        label = fused_data['label']\n",
    "        fused_data = fused_data['data']\n",
    "        #print(fused_data.shape)\n",
    "        processed_data_path = os.path.join(DATA_PATH2, session_id)\n",
    "        processed_data = np.load(processed_data_path)\n",
    "        \n",
    "        tmp = session_id.split(\".\")[0]\n",
    "        tmp = tmp + \".wav_st.npy\"\n",
    "        mfcc_data_path = os.path.join(DATA_PATH3, tmp)\n",
    "        mfcc_data = np.load(mfcc_data_path).T\n",
    "        #print('mfcc data:', mfcc_data.shape)\n",
    "        mfcc_data = mfcc_data[:fused_data.shape[0], 9:22] # MFCC data and data alignment\n",
    "        #mfcc_data = stats.zscore(mfcc_data, axis=0, ddof=1)\n",
    "        #print('final mfcc data', mfcc_data.shape)\n",
    "    \n",
    "        hand_cross_fidget_label_array = fused_data[:, 0].reshape((-1, 1))  # hand cross fidget data\n",
    "        left_hand_arm_label_array = fused_data[:, 1].reshape((-1, 1))\n",
    "        left_hand_leg_label_array = fused_data[:, 2].reshape((-1, 1))\n",
    "        left_hand_face_label_array = fused_data[:, 3].reshape((-1, 1))\n",
    "        right_hand_arm_label_array = fused_data[:, 4].reshape((-1, 1))\n",
    "        right_hand_leg_label_array = fused_data[:, 5].reshape((-1, 1))\n",
    "        right_hand_face_label_array = fused_data[:, 6].reshape((-1, 1))\n",
    "        leg_location_label_array = fused_data[:, 7].reshape((-1, 1))\n",
    "        leg_action_label_array = fused_data[:, 8].reshape((-1, 1))\n",
    "        hand_action_label_array = fused_data[:, 9:11]  # shape (n, 2) NOTE!\n",
    "        speaker_array = fused_data[:, 11].reshape((-1, 1)) # Speaker Identity\n",
    "        voice_array = fused_data[:, 12].reshape((-1, 1)) # Slience (0) or not (1)\n",
    "        \n",
    "        left_hand_to_leg_fidget_array = np.zeros((fused_data.shape[0], 1))\n",
    "        left_hand_to_leg_fidget_array[\n",
    "            (hand_action_label_array[:, 0].reshape((-1, 1)) == 1) & (left_hand_leg_label_array == 1)] = 1\n",
    "\n",
    "        right_hand_to_leg_fidget_array = np.zeros((fused_data.shape[0], 1))\n",
    "        right_hand_to_leg_fidget_array[\n",
    "            (hand_action_label_array[:, 1].reshape((-1, 1)) == 1) & (right_hand_leg_label_array == 1)] = 1\n",
    "\n",
    "        left_hand_to_arm_fidget_array = np.zeros((fused_data.shape[0], 1))\n",
    "        left_hand_to_arm_fidget_array[\n",
    "            (hand_action_label_array[:, 0].reshape((-1, 1)) == 1) & (left_hand_arm_label_array == 1)] = 1\n",
    "\n",
    "        right_hand_to_arm_fidget_array = np.zeros((fused_data.shape[0], 1))\n",
    "        right_hand_to_arm_fidget_array[\n",
    "            (hand_action_label_array[:, 1].reshape((-1, 1)) == 1) & (right_hand_arm_label_array == 1)] = 1\n",
    "\n",
    "        left_hand_to_face_fidget_array = np.zeros((fused_data.shape[0], 1))\n",
    "        left_hand_to_face_fidget_array[\n",
    "            (hand_action_label_array[:, 0].reshape((-1, 1)) == 1) & (left_hand_face_label_array == 1)] = 1\n",
    "\n",
    "        right_hand_to_face_fidget_array = np.zeros((fused_data.shape[0], 1))\n",
    "        right_hand_to_face_fidget_array[\n",
    "            (hand_action_label_array[:, 1].reshape((-1, 1)) == 1) & (right_hand_face_label_array == 1)] = 1\n",
    "\n",
    "        leg_fidget_array = leg_action_label_array\n",
    "        leg_fidget_array[leg_fidget_array > 1] = 1\n",
    "        leg_fidget_array = np.array(savgol_filter(leg_fidget_array.reshape(-1).tolist(), 51, 3)).reshape(\n",
    "            (-1, 1))\n",
    "        leg_fidget_array[leg_fidget_array >= 0.8] = 1\n",
    "        leg_fidget_array[leg_fidget_array < 0.8] = 0\n",
    "\n",
    "        speaking_array = np.zeros((fused_data.shape[0], 1))\n",
    "        for speaker_label in speaker_label_data[int(ids)][int(sess)]:\n",
    "            speaking_array[(speaker_array == speaker_label)] = 1\n",
    "        speaking_array[voice_array == 0] = 0\n",
    "        \n",
    "        # suppress signal when not speaking\n",
    "        hand_cross_fidget_label_array[speaking_array == 0] = 0\n",
    "        left_hand_to_leg_fidget_array[speaking_array == 0] = 0\n",
    "        right_hand_to_leg_fidget_array[speaking_array == 0] = 0\n",
    "        left_hand_to_arm_fidget_array[speaking_array == 0] = 0\n",
    "        right_hand_to_arm_fidget_array[speaking_array == 0] = 0\n",
    "        left_hand_to_face_fidget_array[speaking_array == 0] = 0\n",
    "        right_hand_to_face_fidget_array[speaking_array == 0] = 0\n",
    "        leg_fidget_array[speaking_array == 0] = 0\n",
    "        \n",
    "        #print(processed_data.shape)\n",
    "        \n",
    "        # Gaze data\n",
    "        gaze_data = processed_data[:, list(range(274, 282))]\n",
    "        gaze_data = stats.zscore(gaze_data, axis=0, ddof=1)\n",
    "        \n",
    "        # AU data\n",
    "        AUs_data = processed_data[:, list(range(948, 983))]\n",
    "        \n",
    "        combined_data = np.hstack((\n",
    "            hand_cross_fidget_label_array, #1\n",
    "            left_hand_to_leg_fidget_array, #1\n",
    "            right_hand_to_leg_fidget_array,#1\n",
    "            left_hand_to_arm_fidget_array,#1\n",
    "            right_hand_to_arm_fidget_array,#1\n",
    "            left_hand_to_face_fidget_array,#1\n",
    "            right_hand_to_face_fidget_array,#1\n",
    "            leg_fidget_array,#1\n",
    "            speaking_array,#1\n",
    "            gaze_data,#8\n",
    "            AUs_data,#35\n",
    "            mfcc_data,#13\n",
    "        ))\n",
    "        \n",
    "        print (combined_data.shape)\n",
    "        label_column = [label] * combined_data.shape[0]\n",
    "        combined_data = np.column_stack((combined_data, label_column))\n",
    "        print (combined_data.shape)\n",
    "        \n",
    "        save_path = os.path.join(DATA_PATH4, session_id)\n",
    "        print (save_path)\n",
    "        np.save(save_path, combined_data)\n",
    "        #fidget = combined_data[:,:9]\n",
    "        #gaze = combined_data[:,9:17]\n",
    "        #au = combined_data[:,17:52]\n",
    "        #mfcc = combined_data[:,52:]\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"AllData\"\n",
    "DATA_PATH2 = \"TemporalData60\"\n",
    "onlyfiles = [f for f in listdir(DATA_PATH) if isfile(join(DATA_PATH, f))]\n",
    "\n",
    "def get_dynamics(X_0th, time=0.1):\n",
    "    \"\"\"compute dynamics for data (1st)\"\"\"\n",
    "    X_1st = np.zeros((X_0th.shape[0]-1, X_0th.shape[1]))\n",
    "    for i in range(X_0th.shape[0]-1):\n",
    "        X_1st[i] = (X_0th[i+1] - X_0th[i]) / time\n",
    "    return X_1st\n",
    "\n",
    "for i in range(len(onlyfiles)):\n",
    "    \n",
    "    tmp = np.load(os.path.join(DATA_PATH, onlyfiles[i]))\n",
    "    label = tmp[:, -1]\n",
    "    tmp = get_dynamics(tmp)\n",
    "    tmp[:, -1] = label[1:]\n",
    "    \n",
    "    look_back = 60\n",
    "    nb_samples = tmp.shape[0] - look_back\n",
    "    x_train_reshaped = np.zeros((nb_samples, look_back, tmp.shape[1]))\n",
    "\n",
    "    for k in range(nb_samples):\n",
    "        y_position = k + look_back\n",
    "        x_train_reshaped[k] = tmp[k:y_position]\n",
    "    \n",
    "        \n",
    "    save_path = os.path.join(DATA_PATH2, onlyfiles[i])\n",
    "    np.save(save_path, x_train_reshaped)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
